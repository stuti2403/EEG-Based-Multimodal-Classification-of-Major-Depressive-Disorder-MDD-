{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67fbde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat \n",
    "import mne, glob \n",
    "import pandas as pd\n",
    "import mat73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d6399",
   "metadata": {},
   "source": [
    "## resting state HC vs MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "865956e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "(53, 2688)\n",
      "(53,)\n",
      "[1 0 0 1 0 1 1 0 1 0 1]\n",
      "[[4 1]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.66      0.65      0.63        11\n",
      "weighted avg       0.67      0.64      0.63        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# Encode labels (MDD -> 1, HC -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8835640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[5 0]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.81      0.75      0.72        11\n",
      "weighted avg       0.83      0.73      0.71        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e069c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[5 0]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.81      0.75      0.72        11\n",
      "weighted avg       0.83      0.73      0.71        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7eea72ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[4 1]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.82      0.82      0.82        11\n",
      "weighted avg       0.82      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5eae543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[4 1]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.93      0.90      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f20f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[1 4]\n",
      " [4 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.20      0.20         5\n",
      "           1       0.33      0.33      0.33         6\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.27      0.27      0.27        11\n",
      "weighted avg       0.27      0.27      0.27        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbee8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[5 0]\n",
      " [4 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71         5\n",
      "           1       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.78      0.67      0.61        11\n",
      "weighted avg       0.80      0.64      0.60        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1475b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4dcd233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[5 0]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.81      0.75      0.72        11\n",
      "weighted avg       0.83      0.73      0.71        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6be6b2",
   "metadata": {},
   "source": [
    "## dot probe state HC vs MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "422a8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "(53, 2688)\n",
      "(53,)\n",
      "[1 0 0 1 0 1 1 0 1 0 1]\n",
      "[[2 3]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.65      0.62      0.61        11\n",
      "weighted avg       0.64      0.64      0.62        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# Encode labels (MDD -> 1, HC -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "713e872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[2 3]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.65      0.62      0.61        11\n",
      "weighted avg       0.64      0.64      0.62        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "138bf749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[2 3]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.65      0.62      0.61        11\n",
      "weighted avg       0.64      0.64      0.62        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91137749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[3 2]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.88      0.80      0.80        11\n",
      "weighted avg       0.86      0.82      0.81        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33d3990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[4 1]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.66      0.65      0.63        11\n",
      "weighted avg       0.67      0.64      0.63        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1c8063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[2 3]\n",
      " [2 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44         5\n",
      "           1       0.57      0.67      0.62         6\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.54      0.53      0.53        11\n",
      "weighted avg       0.54      0.55      0.54        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbf2e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[4 1]\n",
      " [3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.66      0.65      0.63        11\n",
      "weighted avg       0.67      0.64      0.63        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31b35e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[3 2]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.73      0.72      0.72        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365fbe6",
   "metadata": {},
   "source": [
    "## resting state HC vs Task State HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ee6c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(29, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_ts = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data_ts.shape)\n",
    "data_ts_HC=data_ts.iloc[24:,1:-1]\n",
    "#data_ts_HC_labels=data_ts.iloc[24:,-1]\n",
    "print(data_ts_HC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9348d42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(29, 2688)\n"
     ]
    }
   ],
   "source": [
    "data_rs = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data_rs.shape)\n",
    "data_rs_HC=data_rs.iloc[24:,1:-1]\n",
    "#data_rs_HC_labels=data_rs.iloc[24:,-1]\n",
    "print(data_rs_HC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a49ced61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rs_HC_labels=np.zeros(data_rs_HC.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf319432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_rs_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aae2fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_ts_HC_labels=np.ones(data_ts_HC.shape[0])\n",
    "print(data_ts_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37f5e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features=np.concatenate((data_rs_HC,data_ts_HC),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e997329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 2688)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a8d8388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels=np.concatenate((data_rs_HC_labels,data_ts_HC_labels),axis=0)\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5d994ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_features\n",
    "y=all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f1b8331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      "[[6 0]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbc32613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[5 1]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91         6\n",
      "         1.0       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.93      0.92      0.92        12\n",
      "weighted avg       0.93      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a308825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[5 1]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91         6\n",
      "         1.0       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.93      0.92      0.92        12\n",
      "weighted avg       0.93      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3cf1b578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[5 1]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83         6\n",
      "         1.0       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1bf15f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[3 3]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         6\n",
      "         1.0       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.83      0.75      0.73        12\n",
      "weighted avg       0.83      0.75      0.73        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b4b3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[6 0]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92         6\n",
      "         1.0       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.93      0.92      0.92        12\n",
      "weighted avg       0.93      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "33791fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[4 2]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5be3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[2 4]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44         6\n",
      "         1.0       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.61      0.58      0.56        12\n",
      "weighted avg       0.61      0.58      0.56        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41f9dd",
   "metadata": {},
   "source": [
    "## resting state MDD vs task state MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c829d128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(24, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_ts = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data_ts.shape)\n",
    "data_ts_MDD=data_ts.iloc[:24,1:-1]\n",
    "#data_ts_HC_labels=data_ts.iloc[24:,-1]\n",
    "print(data_ts_MDD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "665aa649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(24, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_rs = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data_rs.shape)\n",
    "data_rs_MDD=data_rs.iloc[:24,1:-1]\n",
    "#data_rs_HC_labels=data_rs.iloc[24:,-1]\n",
    "print(data_rs_MDD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9e7701c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_ts_MDD_labels=np.ones(data_ts_MDD.shape[0])\n",
    "print(data_ts_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89dd0420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "data_rs_MDD_labels=np.zeros(data_rs_MDD.shape[0])\n",
    "print(data_rs_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b6d6cbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 2688)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features=np.concatenate((data_rs_MDD,data_ts_MDD),axis=0)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1cae8690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels=np.concatenate((data_rs_MDD_labels,data_ts_MDD_labels),axis=0)\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e8f7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_features\n",
    "y=all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "336253da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[[3 0]\n",
      " [1 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         3\n",
      "         1.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.88      0.93      0.89        10\n",
      "weighted avg       0.93      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ebd2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[3 0]\n",
      " [3 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         3\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.75      0.79      0.70        10\n",
      "weighted avg       0.85      0.70      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a48800c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[3 0]\n",
      " [3 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         3\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.75      0.79      0.70        10\n",
      "weighted avg       0.85      0.70      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5fbbbcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[2 1]\n",
      " [3 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.67      0.50         3\n",
      "         1.0       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.60      0.62      0.58        10\n",
      "weighted avg       0.68      0.60      0.62        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6af4bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[2 1]\n",
      " [1 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67         3\n",
      "         1.0       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfabcab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[3 0]\n",
      " [3 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         3\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.75      0.79      0.70        10\n",
      "weighted avg       0.85      0.70      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "072a01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[2 1]\n",
      " [2 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.67      0.57         3\n",
      "         1.0       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.67      0.69      0.67        10\n",
      "weighted avg       0.73      0.70      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1d95c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[3 0]\n",
      " [3 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         3\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.75      0.79      0.70        10\n",
      "weighted avg       0.85      0.70      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef679d96",
   "metadata": {},
   "source": [
    "## resting state MDD VS task state HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b46cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2688)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(data_ts_HC.shape)\n",
    "print(data_ts_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3b21013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2688)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_rs_MDD.shape)\n",
    "print(data_rs_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bea10363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2688)\n"
     ]
    }
   ],
   "source": [
    "all_features=np.concatenate((data_rs_MDD,data_ts_HC),axis=0)\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "664f0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53,)\n"
     ]
    }
   ],
   "source": [
    "all_labels=np.concatenate((data_rs_MDD_labels,data_ts_HC_labels),axis=0)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1a030e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_features\n",
    "y=all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7054fd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "905602a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de131000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbe8220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[6 0]\n",
      " [1 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92         6\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.93      0.90      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "25da747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[5 1]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91         6\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.92      0.92      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01d17051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4dcc0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[4 2]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.86      0.83      0.82        11\n",
      "weighted avg       0.87      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aca636b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[4 2]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.86      0.83      0.82        11\n",
      "weighted avg       0.87      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4c90e",
   "metadata": {},
   "source": [
    "## task state MDD VS resting state HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "773228eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2688)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(data_ts_MDD.shape)\n",
    "print(data_ts_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef21d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2688)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_rs_HC.shape)\n",
    "print(data_rs_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ef4304ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test)\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8da60f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "86ec3af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e14b50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[6 0]\n",
      " [1 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92         6\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.93      0.90      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ae92054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[5 1]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91         6\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.92      0.92      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cf7bcebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[6 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "926576c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[4 2]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.86      0.83      0.82        11\n",
      "weighted avg       0.87      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "573b645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[4 2]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.86      0.83      0.82        11\n",
      "weighted avg       0.87      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab967f00",
   "metadata": {},
   "source": [
    "## common subjects only classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced52b21",
   "metadata": {},
   "source": [
    "## resting state HC and MDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2d892",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3645262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "shape after scaling\n",
      "(38, 2688)\n",
      "shape after reshaping\n",
      "(38, 1, 2688)\n",
      "[1 1 1 0 0 0 0 0]\n",
      "[1 1 1 1 1 0 0 0]\n",
      "[1 1 1 1 0 0 0 0]\n",
      "[1 1 0 0 0 0 0]\n",
      "[1 1 1 0 0 0 0]\n",
      "Average Accuracy: 52.86%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.62      0.38      0.47        21\n",
      "         MDD       0.48      0.71      0.57        17\n",
      "\n",
      "    accuracy                           0.53        38\n",
      "   macro avg       0.55      0.54      0.52        38\n",
      "weighted avg       0.55      0.53      0.52        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "import random\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "X = data.iloc[indices,1:-1]\n",
    "y = data.iloc[indices, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"shape after scaling\")\n",
    "print(X_scaled.shape)\n",
    "\n",
    "\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "print(\"shape after reshaping\")\n",
    "print(X_reshaped.shape)\n",
    "#Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define number of splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to hold results\n",
    "accuracy_list = []\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    print(y_test)\n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2,callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Predict and store results\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_true_list.extend(y_test)\n",
    "    y_pred_list.extend(y_pred)\n",
    "\n",
    "# Print average accuracy\n",
    "print(f'Average Accuracy: {np.mean(accuracy_list) * 100:.2f}%')\n",
    "\n",
    "# Print the classification report for all folds\n",
    "print(classification_report(y_true_list, y_pred_list, target_names=['HC', 'MDD']))\n",
    "\n",
    "\n",
    "\n",
    "# # Build the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(32, return_sequences=False))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "125186ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "shape after scaling\n",
      "(38, 2688)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "import random\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "X = data.iloc[indices,1:-1]\n",
    "y = data.iloc[indices, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"shape after scaling\")\n",
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec8cb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reshape X for LSTM\n",
    "X = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "481e3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "191cc51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.6985 - accuracy: 0.5417 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6884 - accuracy: 0.5833 - val_loss: 0.7025 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6854 - accuracy: 0.6667 - val_loss: 0.7068 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.6810 - accuracy: 0.6250 - val_loss: 0.7118 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.6767 - accuracy: 0.5833 - val_loss: 0.7174 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.6819 - accuracy: 0.6250 - val_loss: 0.7240 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.6675 - accuracy: 0.6250 - val_loss: 0.7311 - val_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.6619 - accuracy: 0.6250 - val_loss: 0.7396 - val_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.6634 - accuracy: 0.6250 - val_loss: 0.7499 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.6686 - accuracy: 0.6250 - val_loss: 0.7609 - val_accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6650 - accuracy: 0.5833 - val_loss: 0.7723 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc42bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6920 - accuracy: 0.5000\n",
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2fd972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_18884\\3500737624.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=16, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.6934 - accuracy: 0.4333 - val_loss: 0.6955 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.6946 - accuracy: 0.4667 - val_loss: 0.6933 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6905 - accuracy: 0.5333 - val_loss: 0.6906 - val_accuracy: 0.6250\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6953 - accuracy: 0.4000 - val_loss: 0.6875 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6955 - accuracy: 0.4333 - val_loss: 0.6863 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6883 - accuracy: 0.5333 - val_loss: 0.6843 - val_accuracy: 0.6250\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6955 - accuracy: 0.5667 - val_loss: 0.6835 - val_accuracy: 0.6250\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6893 - accuracy: 0.5333 - val_loss: 0.6826 - val_accuracy: 0.6250\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6873 - accuracy: 0.5333 - val_loss: 0.6822 - val_accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6884 - accuracy: 0.5000 - val_loss: 0.6822 - val_accuracy: 0.6250\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6963 - accuracy: 0.5000 - val_loss: 0.6816 - val_accuracy: 0.6250\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6910 - accuracy: 0.5333 - val_loss: 0.6812 - val_accuracy: 0.6250\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6915 - accuracy: 0.5333 - val_loss: 0.6808 - val_accuracy: 0.6250\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6975 - accuracy: 0.5000 - val_loss: 0.6806 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6894 - accuracy: 0.5333 - val_loss: 0.6804 - val_accuracy: 0.6250\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6801 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6895 - accuracy: 0.5333 - val_loss: 0.6798 - val_accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6853 - accuracy: 0.5333 - val_loss: 0.6787 - val_accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6896 - accuracy: 0.4667 - val_loss: 0.6775 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6852 - accuracy: 0.5333 - val_loss: 0.6763 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6861 - accuracy: 0.5333 - val_loss: 0.6763 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6854 - accuracy: 0.5333 - val_loss: 0.6749 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6922 - accuracy: 0.5333 - val_loss: 0.6748 - val_accuracy: 0.6250\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6793 - accuracy: 0.5667 - val_loss: 0.6748 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6862 - accuracy: 0.5333 - val_loss: 0.6744 - val_accuracy: 0.6250\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6820 - accuracy: 0.5333 - val_loss: 0.6748 - val_accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6865 - accuracy: 0.5333 - val_loss: 0.6750 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6728 - accuracy: 0.5333 - val_loss: 0.6753 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6965 - accuracy: 0.5000 - val_loss: 0.6725 - val_accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6772 - accuracy: 0.5333 - val_loss: 0.6703 - val_accuracy: 0.6250\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6905 - accuracy: 0.5667 - val_loss: 0.6633 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6708 - accuracy: 0.5333 - val_loss: 0.6489 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6942 - accuracy: 0.5333 - val_loss: 0.6336 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6648 - accuracy: 0.5333 - val_loss: 0.6199 - val_accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6691 - accuracy: 0.5333 - val_loss: 0.6015 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6679 - accuracy: 0.5667 - val_loss: 0.6215 - val_accuracy: 0.6250\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6518 - accuracy: 0.5333 - val_loss: 0.5183 - val_accuracy: 0.6250\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6801 - accuracy: 0.5333 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 0.6835 - val_accuracy: 0.6250\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6684 - accuracy: 0.5667 - val_loss: 0.6962 - val_accuracy: 0.6250\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6793 - accuracy: 0.5333 - val_loss: 0.7047 - val_accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6829 - accuracy: 0.5000 - val_loss: 0.7138 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6688 - accuracy: 0.6667 - val_loss: 0.7257 - val_accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6760 - accuracy: 0.5333 - val_loss: 0.7330 - val_accuracy: 0.6250\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6899 - accuracy: 0.4333 - val_loss: 0.7281 - val_accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6707 - accuracy: 0.6667 - val_loss: 0.7225 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6769 - accuracy: 0.5333 - val_loss: 0.7212 - val_accuracy: 0.5000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5183 - accuracy: 0.6250\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 13s 6s/step - loss: 0.6973 - accuracy: 0.4000 - val_loss: 0.6998 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6875 - accuracy: 0.6667 - val_loss: 0.7014 - val_accuracy: 0.3750\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6958 - accuracy: 0.5667 - val_loss: 0.7042 - val_accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6889 - accuracy: 0.5667 - val_loss: 0.7057 - val_accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6857 - accuracy: 0.6000 - val_loss: 0.7071 - val_accuracy: 0.3750\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6756 - accuracy: 0.6000 - val_loss: 0.7090 - val_accuracy: 0.3750\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6677 - accuracy: 0.6333 - val_loss: 0.7098 - val_accuracy: 0.3750\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6760 - accuracy: 0.6000 - val_loss: 0.7117 - val_accuracy: 0.3750\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6773 - accuracy: 0.5667 - val_loss: 0.7130 - val_accuracy: 0.3750\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6682 - accuracy: 0.6000 - val_loss: 0.7144 - val_accuracy: 0.3750\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6496 - accuracy: 0.6000 - val_loss: 0.7157 - val_accuracy: 0.3750\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6998 - accuracy: 0.2500\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 14s 6s/step - loss: 0.6912 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6881 - accuracy: 0.5333 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6880 - accuracy: 0.5333 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6881 - accuracy: 0.6000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6816 - accuracy: 0.5667 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6812 - accuracy: 0.5333 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6793 - accuracy: 0.6000 - val_loss: 0.7014 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6639 - accuracy: 0.5667 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6788 - accuracy: 0.5667 - val_loss: 0.7237 - val_accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6420 - accuracy: 0.5667 - val_loss: 0.7418 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6352 - accuracy: 0.5333 - val_loss: 0.7895 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6448 - accuracy: 0.5333 - val_loss: 0.8847 - val_accuracy: 0.5000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6929 - accuracy: 0.5000\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 14s 6s/step - loss: 0.6942 - accuracy: 0.5806 - val_loss: 0.6908 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6845 - accuracy: 0.5484 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6931 - accuracy: 0.5484 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6902 - accuracy: 0.5806 - val_loss: 0.6833 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6909 - accuracy: 0.5484 - val_loss: 0.6800 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6887 - accuracy: 0.5161 - val_loss: 0.6780 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6852 - accuracy: 0.5161 - val_loss: 0.6760 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6822 - accuracy: 0.5484 - val_loss: 0.6740 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6827 - accuracy: 0.5484 - val_loss: 0.6715 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6859 - accuracy: 0.5484 - val_loss: 0.6698 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6803 - accuracy: 0.5484 - val_loss: 0.6674 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6752 - accuracy: 0.5484 - val_loss: 0.6641 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6794 - accuracy: 0.5806 - val_loss: 0.6586 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6728 - accuracy: 0.5484 - val_loss: 0.6538 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6893 - accuracy: 0.5806 - val_loss: 0.6534 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6484 - accuracy: 0.5806 - val_loss: 0.6525 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6928 - accuracy: 0.6452 - val_loss: 0.6521 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6508 - accuracy: 0.6452 - val_loss: 0.6540 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6701 - accuracy: 0.6129 - val_loss: 0.6566 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6499 - accuracy: 0.6129 - val_loss: 0.6581 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6798 - accuracy: 0.5806 - val_loss: 0.6588 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6511 - accuracy: 0.6129 - val_loss: 0.6560 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6538 - accuracy: 0.6129 - val_loss: 0.6574 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6345 - accuracy: 0.6129 - val_loss: 0.6662 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6742 - accuracy: 0.6452 - val_loss: 0.6546 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6663 - accuracy: 0.5806 - val_loss: 0.6578 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6549 - accuracy: 0.6774 - val_loss: 0.6616 - val_accuracy: 0.5714\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6521 - accuracy: 0.5714\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 14s 6s/step - loss: 0.6926 - accuracy: 0.5484 - val_loss: 0.7052 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6865 - accuracy: 0.5806 - val_loss: 0.7186 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6816 - accuracy: 0.6452 - val_loss: 0.7336 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.6754 - accuracy: 0.5806 - val_loss: 0.7502 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6712 - accuracy: 0.6129 - val_loss: 0.7685 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6555 - accuracy: 0.6452 - val_loss: 0.7923 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6571 - accuracy: 0.6129 - val_loss: 0.8214 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6393 - accuracy: 0.6129 - val_loss: 0.8606 - val_accuracy: 0.2857\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6102 - accuracy: 0.6129 - val_loss: 0.9198 - val_accuracy: 0.2857\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6024 - accuracy: 0.6129 - val_loss: 0.9906 - val_accuracy: 0.2857\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6436 - accuracy: 0.6452 - val_loss: 1.0365 - val_accuracy: 0.2857\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7052 - accuracy: 0.5714\n",
      "Mean Test Accuracy: 0.5036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model for use with scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Implement K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    results.append(test_acc)\n",
    "\n",
    "print(f'Mean Test Accuracy: {np.mean(results):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824661e4",
   "metadata": {},
   "source": [
    "# making 20% of the data unseen to avoid overfitting and then training with stratified k fold cross validation on 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa4a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "shape after scaling\n",
      "(38, 2688)\n",
      "shape after reshaping\n",
      "(38, 1, 2688)\n",
      "Processing Fold 1\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 5s 559ms/step - loss: 0.7015 - accuracy: 0.5417 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6774 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6571 - accuracy: 0.7083 - val_loss: 0.6658 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6146 - accuracy: 0.7917 - val_loss: 0.6603 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6136 - accuracy: 0.7500 - val_loss: 0.6549 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5716 - accuracy: 0.8750 - val_loss: 0.6525 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5634 - accuracy: 0.9167 - val_loss: 0.6453 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5944 - accuracy: 0.7500 - val_loss: 0.6305 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5272 - accuracy: 0.9167 - val_loss: 0.6298 - val_accuracy: 0.8333\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5218 - accuracy: 0.9167 - val_loss: 0.6261 - val_accuracy: 0.8333\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5099 - accuracy: 0.9167 - val_loss: 0.6141 - val_accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4662 - accuracy: 0.9167 - val_loss: 0.6033 - val_accuracy: 0.8333\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4336 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8333\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4172 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4158 - accuracy: 0.9583 - val_loss: 0.5490 - val_accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3748 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8333\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3473 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.8333\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3214 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.8333\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3051 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8333\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2786 - accuracy: 0.9583 - val_loss: 0.4609 - val_accuracy: 0.8333\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2303 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8333\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8333\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8333\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2228 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.8333\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8333\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1865 - accuracy: 0.9583 - val_loss: 0.3955 - val_accuracy: 0.8333\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.8333\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1258 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.8333\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1159 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8333\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1213 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.8333\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.8333\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.8333\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.8333\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.8333\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.8333\n",
      "Fold 1 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n",
      "[[3 1]\n",
      " [0 2]]\n",
      "Processing Fold 2\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 497ms/step - loss: 0.6823 - accuracy: 0.6250 - val_loss: 0.7014 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6508 - accuracy: 0.7083 - val_loss: 0.7048 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5808 - accuracy: 0.9167 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5937 - accuracy: 0.7917 - val_loss: 0.7202 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5706 - accuracy: 0.8750 - val_loss: 0.7300 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5035 - accuracy: 0.8750 - val_loss: 0.7339 - val_accuracy: 0.5000\n",
      "Fold 2 Accuracy: 0.4444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.38      0.38      0.33         6\n",
      "weighted avg       0.42      0.33      0.33         6\n",
      "\n",
      "[[1 3]\n",
      " [1 1]]\n",
      "Processing Fold 3\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 561ms/step - loss: 0.6775 - accuracy: 0.5833 - val_loss: 0.7060 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6257 - accuracy: 0.7500 - val_loss: 0.7182 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6172 - accuracy: 0.8750 - val_loss: 0.7347 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6099 - accuracy: 0.7917 - val_loss: 0.7376 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5852 - accuracy: 0.9583 - val_loss: 0.7444 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5579 - accuracy: 0.9167 - val_loss: 0.7640 - val_accuracy: 0.3333\n",
      "Fold 3 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33         3\n",
      "           1       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.33      0.33      0.33         6\n",
      "weighted avg       0.33      0.33      0.33         6\n",
      "\n",
      "[[1 2]\n",
      " [2 1]]\n",
      "Processing Fold 4\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 523ms/step - loss: 0.6870 - accuracy: 0.4583 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6587 - accuracy: 0.7083 - val_loss: 0.6777 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5908 - accuracy: 0.8333 - val_loss: 0.6792 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5668 - accuracy: 0.9583 - val_loss: 0.6813 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5764 - accuracy: 0.8333 - val_loss: 0.6763 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5145 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5317 - accuracy: 0.8333 - val_loss: 0.6596 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5081 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4712 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4621 - accuracy: 0.9167 - val_loss: 0.6344 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4457 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4097 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3505 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3935 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3726 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3140 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3002 - accuracy: 0.9583 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2704 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2422 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.8333\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1940 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1806 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1702 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.8333\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8333\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8333\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1384 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.6667\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.6667\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1129 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.5428 - val_accuracy: 0.6667\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.6667\n",
      "Fold 4 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "[[3 0]\n",
      " [2 1]]\n",
      "Processing Fold 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 418ms/step - loss: 0.7194 - accuracy: 0.3750 - val_loss: 0.6970 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6581 - accuracy: 0.6667 - val_loss: 0.6949 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6229 - accuracy: 0.7500 - val_loss: 0.6907 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5903 - accuracy: 0.9583 - val_loss: 0.6794 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5765 - accuracy: 0.9583 - val_loss: 0.6684 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5297 - accuracy: 0.9583 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5290 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5219 - accuracy: 0.9583 - val_loss: 0.6248 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4801 - accuracy: 0.9167 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4340 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4268 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3949 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3642 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3767 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3603 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2933 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2896 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1879 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1729 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1269 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1867 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.6667\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.6667\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.6667\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.6667\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.6667\n",
      "Fold 5 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "[[3 0]\n",
      " [2 1]]\n",
      "Cross-validation Accuracies: [0.5, 0.4444444444444444, 0.5, 0.5, 0.5]\n",
      "Mean Cross-validation Accuracy: 0.48888888888888893\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.8421WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 2s 13ms/step - loss: 0.2655 - accuracy: 0.8421\n",
      "Epoch 2/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1791 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.9211\n",
      "Epoch 3/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1216 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2511 - accuracy: 0.9474\n",
      "Epoch 4/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1885 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2238 - accuracy: 0.9474\n",
      "Epoch 5/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0768 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2138 - accuracy: 0.9737\n",
      "Epoch 6/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1828 - accuracy: 0.8750WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1855 - accuracy: 0.9474\n",
      "Epoch 7/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2817 - accuracy: 0.8750WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1534 - accuracy: 0.9737\n",
      "Epoch 8/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0673 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9737\n",
      "Epoch 9/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1547 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1663 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1180 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2450 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1324 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2406 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0928 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1144 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0720 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0996 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0975 - accuracy: 0.9737\n",
      "Epoch 17/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0387 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0735 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0530 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0504 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1162 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0906 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0743 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0793 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0541 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0507 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0465 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0328 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0475 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0377 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0378 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0314 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0704 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0256 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0331 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Final Model Evaluation on Unseen Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n",
      "Final Model Evaluation on 20% Test Split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[indices, 1:-1].values  # Features\n",
    "y = data.iloc[indices, -1].values    # Labels\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"shape after scaling\")\n",
    "print(X_scaled.shape)\n",
    "\n",
    "\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "print(\"shape after reshaping\")\n",
    "print(X_reshaped.shape)\n",
    "\n",
    "# Split the data into two parts: 80% training (part1) and 20% unseen (part2)\n",
    "X_part1, X_part2, y_part1, y_part2 = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "\n",
    "# Cross-validation setup on the first part of the data\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "fold_accuracies = []\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_part1, y_part1)):\n",
    "    print(f\"Processing Fold {fold + 1}\")\n",
    "    X_train, X_val = X_part1[train_index], X_part1[val_index]\n",
    "    y_train, y_val = y_part1[train_index], y_part1[val_index]\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    accuracy = np.mean(y_pred == y_val)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"Cross-validation Accuracies:\", fold_accuracies)\n",
    "print(\"Mean Cross-validation Accuracy:\", np.mean(fold_accuracies))\n",
    "\n",
    "# # Train the final model on the entire dataset (X_part1 + X_part2)\n",
    "# final_model = create_cnn_model()\n",
    "X_combined_reshaped = np.concatenate([X_part1, X_part2], axis=0)\n",
    "y_combined = np.concatenate([y_part1, y_part2], axis=0)\n",
    "model.fit(X_combined_reshaped, y_combined, epochs=50, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the final model on the unseen part (X_part2)\n",
    "y_pred_final = (model.predict(X_part2) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on Unseen Data:\")\n",
    "print(classification_report(y_part2, y_pred_final))\n",
    "print(confusion_matrix(y_part2, y_pred_final))\n",
    "\n",
    "# Optionally, you can also split the entire data into 80:20 again and test on that split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_combined_reshaped, y_combined, test_size=0.2, random_state=42, stratify=y_combined)\n",
    "y_pred_test_full = (model.predict(X_test_full) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on 20% Test Split:\")\n",
    "print(classification_report(y_test_full, y_pred_test_full))\n",
    "print(confusion_matrix(y_test_full, y_pred_test_full))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35cd8d",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "605a3f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 520ms/step - loss: 1.3474 - accuracy: 0.5000 - val_loss: 24.8668 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 4.1002 - accuracy: 0.5000 - val_loss: 0.5204 - val_accuracy: 0.8333\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 3.6618 - accuracy: 0.5000 - val_loss: 6.9857 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.0666 - accuracy: 0.7500 - val_loss: 42.1154 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.7467 - accuracy: 0.7917 - val_loss: 70.6054 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.5849 - accuracy: 0.7500 - val_loss: 81.2758 - val_accuracy: 0.1667\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 84.5991 - val_accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.4574 - accuracy: 0.3750\n",
      "Test Accuracy: 37.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.50      0.20      0.29         5\n",
      "         MDD       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.42      0.43      0.37         8\n",
      "weighted avg       0.44      0.38      0.35         8\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "X = data.iloc[indices,1:-1]\n",
    "y = data.iloc[indices, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for Transformer (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Build the Transformer model\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2,callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d31e05a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "shape after scaling\n",
      "(30, 2688)\n",
      "(8, 2688)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "X = data.iloc[indices,1:-1]\n",
    "y = data.iloc[indices, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Normalize the data (optional but recommended)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"shape after scaling\")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bf506b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "927c0adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 34s 9s/step - loss: 0.6931 - accuracy: 0.6250 - val_loss: 0.6935 - val_accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 27s 10s/step - loss: 0.6928 - accuracy: 0.6250 - val_loss: 0.6938 - val_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6925 - accuracy: 0.6250 - val_loss: 0.6940 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6924 - accuracy: 0.6250 - val_loss: 0.6944 - val_accuracy: 0.3333\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6922 - accuracy: 0.6250 - val_loss: 0.6947 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.6920 - accuracy: 0.6250 - val_loss: 0.6950 - val_accuracy: 0.3333\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Test Loss: 0.6931, Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define transformer model\n",
    "def transformer_block(inputs, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=ff_dim, dropout=dropout_rate\n",
    "    )(inputs, inputs)\n",
    "    attention = Dropout(dropout_rate)(attention)\n",
    "    attention = Add()([inputs, attention])\n",
    "    attention = LayerNormalization()(attention)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    ff = Dense(ff_dim, activation='relu')(attention)\n",
    "    ff = Dropout(dropout_rate)(ff)\n",
    "    ff = Dense(inputs.shape[-1])(ff)\n",
    "    ff = Add()([attention, ff])\n",
    "    ff = LayerNormalization()(ff)\n",
    "\n",
    "    return ff\n",
    "\n",
    "def create_transformer_model(input_shape, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = transformer_block(inputs, num_heads, ff_dim, dropout_rate)\n",
    "    x = tf.reduce_mean(x, axis=1)  # Global Average Pooling\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define input shape based on your data\n",
    "input_shape = (X_train.shape[1], 1)  # Assuming a single feature per token\n",
    "X_train_expanded = np.expand_dims(X_train, axis=-1)\n",
    "X_test_expanded = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "model = create_transformer_model(input_shape, num_heads=4, ff_dim=64)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_expanded, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=8, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_expanded, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d725f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 356ms/step - loss: 2.2129 - accuracy: 0.5000 - val_loss: 0.7548 - val_accuracy: 0.6364\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 1.3975 - accuracy: 0.6429 - val_loss: 1.3053 - val_accuracy: 0.6364\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 1.2390 - accuracy: 0.7143 - val_loss: 0.7952 - val_accuracy: 0.6364\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 302ms/step - loss: 0.5364 - accuracy: 0.7857 - val_loss: 0.5520 - val_accuracy: 0.6364\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.5847 - accuracy: 0.7619 - val_loss: 0.7231 - val_accuracy: 0.8182\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.6199 - accuracy: 0.9286 - val_loss: 0.8409 - val_accuracy: 0.5455\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 0.1132 - accuracy: 0.9524 - val_loss: 0.7251 - val_accuracy: 0.7273\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.1035 - accuracy: 0.9524 - val_loss: 0.8230 - val_accuracy: 0.7273\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 0.6502 - accuracy: 0.7619 - val_loss: 4.5752 - val_accuracy: 0.4545\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5520 - accuracy: 0.6364\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 3s 314ms/step - loss: 0.3746 - accuracy: 0.8095 - val_loss: 0.3480 - val_accuracy: 0.8182\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.7759 - accuracy: 0.7619 - val_loss: 0.8540 - val_accuracy: 0.8182\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.2642 - accuracy: 0.8333 - val_loss: 0.9626 - val_accuracy: 0.8182\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 0.3893 - accuracy: 0.8810 - val_loss: 1.0413 - val_accuracy: 0.8182\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 1.4114 - accuracy: 0.7143 - val_loss: 1.8115 - val_accuracy: 0.6364\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 0.6311 - accuracy: 0.7857 - val_loss: 1.7952 - val_accuracy: 0.8182\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3480 - accuracy: 0.8182\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 3s 305ms/step - loss: 0.6319 - accuracy: 0.8333 - val_loss: 0.3936 - val_accuracy: 0.7273\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.7882 - accuracy: 0.7619 - val_loss: 0.2461 - val_accuracy: 0.8182\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 1.0869 - accuracy: 0.8571 - val_loss: 0.1961 - val_accuracy: 0.9091\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.8441 - accuracy: 0.7143 - val_loss: 0.4422 - val_accuracy: 0.5455\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.6040 - accuracy: 0.7857 - val_loss: 0.1443 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 288ms/step - loss: 0.2700 - accuracy: 0.8571 - val_loss: 0.3313 - val_accuracy: 0.8182\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 0.1888 - accuracy: 0.8810 - val_loss: 0.1277 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.1237 - accuracy: 0.9762 - val_loss: 0.1913 - val_accuracy: 0.8182\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.1102 - val_accuracy: 0.9091\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.0779 - accuracy: 0.9762 - val_loss: 0.1983 - val_accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.2630 - val_accuracy: 0.8182\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.0440 - accuracy: 0.9762 - val_loss: 0.3328 - val_accuracy: 0.8182\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.0460 - accuracy: 0.9762 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8182\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.1040 - val_accuracy: 0.9091\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8182\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.0337 - accuracy: 0.9762 - val_loss: 0.6760 - val_accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0462 - accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 3s 312ms/step - loss: 0.1317 - accuracy: 0.9767 - val_loss: 0.1748 - val_accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 288ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9000\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.4069 - accuracy: 0.8837 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.4141 - accuracy: 0.8837 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.3051 - accuracy: 0.9070 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 0.1263 - accuracy: 0.9070 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 0.2350 - accuracy: 0.8605 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.0772 - accuracy: 0.9302 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 3s 282ms/step - loss: 0.0708 - accuracy: 0.9535 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 0.1080 - accuracy: 0.9535 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 3s 302ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 3s 304ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 3s 305ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 3s 315ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 3s 309ms/step - loss: 0.0464 - accuracy: 0.9767 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 3s 315ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 0.0576 - accuracy: 0.9767 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 6.4083e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 6.3796e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 3s 296ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 3s 297ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 3s 302ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 8.9935e-04 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.3796e-04 - accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.0206 - accuracy: 0.9767 - val_loss: 5.0709e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0520e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 314ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.8598e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.0507 - accuracy: 0.9767 - val_loss: 4.6324e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.8868e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 7.2953e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0598e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 321ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.3508e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 9.7258e-04 - accuracy: 1.0000 - val_loss: 3.1093e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3994e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.2070e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3136e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.0013e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 3s 320ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 9.4230e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 8.8259e-04 - accuracy: 1.0000 - val_loss: 8.7173e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.3989e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 3s 319ms/step - loss: 1.1588e-04 - accuracy: 1.0000 - val_loss: 8.0382e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 6.6849e-05 - accuracy: 1.0000 - val_loss: 7.9234e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 8.1060e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 3s 305ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 8.5277e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 3s 297ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.1922e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.3956e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 4s 349ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3538e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.4577e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.0957e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 3s 314ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.9052e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 2.0482e-05 - accuracy: 1.0000 - val_loss: 4.8252e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 3s 319ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7324e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 6.9854e-05 - accuracy: 1.0000 - val_loss: 4.6829e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 8.6828e-04 - accuracy: 1.0000 - val_loss: 4.7169e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 4s 401ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.5932e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 4s 407ms/step - loss: 9.4681e-04 - accuracy: 1.0000 - val_loss: 5.3166e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 6.8531e-04 - accuracy: 1.0000 - val_loss: 4.9607e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 4s 393ms/step - loss: 1.9151e-04 - accuracy: 1.0000 - val_loss: 4.2390e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 4s 406ms/step - loss: 1.0645e-04 - accuracy: 1.0000 - val_loss: 3.9435e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 1.9302e-05 - accuracy: 1.0000 - val_loss: 3.8515e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3921e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 4s 379ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 9.6750e-08 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 4s 356ms/step - loss: 4.4948e-04 - accuracy: 1.0000 - val_loss: 1.4299e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.7764 - accuracy: 0.8837 - val_loss: 1.1307 - val_accuracy: 0.8000\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 0.8161 - accuracy: 0.8605 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 3s 312ms/step - loss: 0.3100 - accuracy: 0.9070 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 0.1076 - accuracy: 0.9767 - val_loss: 0.1923 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.6751e-08 - accuracy: 1.0000\n",
      "Mean Cross-Validation Accuracy: 0.8909090876579284\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 1.8993e-04 - accuracy: 1.0000 - val_loss: 4.9921e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 4s 348ms/step - loss: 3.3904e-05 - accuracy: 1.0000 - val_loss: 4.4182e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.3319e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.0191 - accuracy: 0.9762 - val_loss: 4.6410e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 2.0827e-04 - accuracy: 1.0000 - val_loss: 4.8942e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 317ms/step - loss: 2.4976e-05 - accuracy: 1.0000 - val_loss: 4.9825e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 316ms/step - loss: 9.8726e-04 - accuracy: 1.0000 - val_loss: 5.2002e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 8.7750e-04 - accuracy: 1.0000 - val_loss: 5.3147e-08 - val_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for transformer input\n",
    "X_normalized = X_normalized.reshape((X_normalized.shape[0], 1, X_normalized.shape[1]))  # (samples, 1, features)\n",
    "\n",
    "# Define a simple Transformer block\n",
    "def transformer_block(inputs, num_heads, ff_dim):\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tf.keras.layers.Add()([x, inputs])\n",
    "    x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(inputs.shape[-1])(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tf.keras.layers.Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "# Build the transformer model\n",
    "input_layer = Input(shape=(X_normalized.shape[1], X_normalized.shape[2]))\n",
    "x = transformer_block(input_layer, num_heads=2, ff_dim=64)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_normalized):\n",
    "    X_train, X_val = X_normalized[train_index], X_normalized[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=4,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "    results.append(val_accuracy)\n",
    "\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(results)}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=4,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86c658",
   "metadata": {},
   "source": [
    "# making 20% data unseen at the beginning to avoid overfitting and using rest for stratified k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852fba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Processing Fold 1\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 1.6615 - accuracy: 0.5833 - val_loss: 0.3474 - val_accuracy: 0.8333\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 1.8883 - accuracy: 0.5000 - val_loss: 0.8411 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.5567 - accuracy: 0.8333 - val_loss: 1.1252 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 460ms/step - loss: 0.5729 - accuracy: 0.7500 - val_loss: 0.3155 - val_accuracy: 0.8333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.8351 - accuracy: 0.7083 - val_loss: 0.4864 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.2385 - accuracy: 0.8750 - val_loss: 1.2681 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.4952 - accuracy: 0.8333 - val_loss: 1.1077 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.2140 - accuracy: 0.8750 - val_loss: 0.8190 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.2229 - accuracy: 0.9167 - val_loss: 0.5148 - val_accuracy: 0.8333\n",
      "Fold 1 Accuracy: 0.6111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.90      0.75      0.78         6\n",
      "weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      "[[4 0]\n",
      " [1 1]]\n",
      "Processing Fold 2\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 518ms/step - loss: 0.8354 - accuracy: 0.7500 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.2787 - accuracy: 0.8750 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 437ms/step - loss: 0.6418 - accuracy: 0.7917 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 363ms/step - loss: 0.3569 - accuracy: 0.7917 - val_loss: 0.1308 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 0.1441 - accuracy: 0.9167 - val_loss: 0.1836 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 0.1463 - accuracy: 0.9167 - val_loss: 0.2946 - val_accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 365ms/step - loss: 0.1342 - accuracy: 0.9167 - val_loss: 0.1618 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.2395 - accuracy: 0.9167 - val_loss: 0.7571 - val_accuracy: 0.6667\n",
      "Fold 2 Accuracy: 0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "[[4 0]\n",
      " [0 2]]\n",
      "Processing Fold 3\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 517ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.1794 - accuracy: 0.9167 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 0.2749 - accuracy: 0.9583 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 0.0993 - accuracy: 0.9583 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.1123 - accuracy: 0.9583 - val_loss: 0.2915 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 0.2049 - accuracy: 0.9167 - val_loss: 1.3698 - val_accuracy: 0.6667\n",
      "Fold 3 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "[[3 0]\n",
      " [0 3]]\n",
      "Processing Fold 4\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 0.2292 - accuracy: 0.8333 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 354ms/step - loss: 0.1286 - accuracy: 0.9167 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 363ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 320ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 358ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 360ms/step - loss: 0.1128 - accuracy: 0.9583 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 359ms/step - loss: 0.0768 - accuracy: 0.9583 - val_loss: 0.1370 - val_accuracy: 0.8333\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.8333\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 322ms/step - loss: 0.0657 - accuracy: 0.9583 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Fold 4 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "[[3 0]\n",
      " [0 3]]\n",
      "Processing Fold 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.1046e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 8.0085e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 6.9410e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 5.0077e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 427ms/step - loss: 0.0736 - accuracy: 0.9583 - val_loss: 4.6253e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.0661 - accuracy: 0.9583 - val_loss: 4.7468e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.1700e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 423ms/step - loss: 0.1413 - accuracy: 0.9583 - val_loss: 4.1212e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 3.8818e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 358ms/step - loss: 0.0508 - accuracy: 0.9583 - val_loss: 2.1991e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 0.1136 - accuracy: 0.9583 - val_loss: 1.2373e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 320ms/step - loss: 0.0570 - accuracy: 0.9583 - val_loss: 5.6814e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 2.1060e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 319ms/step - loss: 0.1149 - accuracy: 0.9167 - val_loss: 4.3517e-04 - val_accuracy: 1.0000\n",
      "Fold 5 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "[[3 0]\n",
      " [0 3]]\n",
      "Cross-validation Accuracies: [0.6111111111111112, 0.5555555555555556, 0.5, 0.5, 0.5]\n",
      "Mean Cross-validation Accuracy: 0.5333333333333334\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9799 - accuracy: 0.7895WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 2s 296ms/step - loss: 0.9799 - accuracy: 0.7895\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.3113 - accuracy: 0.8684\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 293ms/step - loss: 0.3393 - accuracy: 0.8947\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.1912 - accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.2303 - accuracy: 0.8947\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9211WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.2740 - accuracy: 0.9211\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.1319 - accuracy: 0.9474\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.1450 - accuracy: 0.9737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.0895 - accuracy: 0.9737\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0507 - accuracy: 0.9737\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0518 - accuracy: 0.9737\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0400 - accuracy: 0.9737\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0189 - accuracy: 0.9737\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3941e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 1.3941e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.3119e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 301ms/step - loss: 6.3119e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2640e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 1.2640e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 277ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 277ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 274ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 5.5734e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 5.5734e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.8324e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 285ms/step - loss: 2.8324e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.1555e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 292ms/step - loss: 2.1555e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7495e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 1.7495e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.9852e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 8.9852e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.3822e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 3.3822e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3683e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 294ms/step - loss: 1.3683e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 5.9763e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 2s 303ms/step - loss: 5.9763e-06 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.1668e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 297ms/step - loss: 4.1668e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 9.4612e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 298ms/step - loss: 9.4612e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.4244e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 297ms/step - loss: 2.4244e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Unseen Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n",
      "Final Model Evaluation on 20% Test Split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for train_index, val_index in kf.split(X_normalized):\n",
    "#     X_train, X_val = X_normalized[train_index], X_normalized[val_index]\n",
    "#     y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "#     history = model.fit(\n",
    "#         X_train, y_train,\n",
    "#         validation_data=(X_val, y_val),\n",
    "#         epochs=50,\n",
    "#         batch_size=4,\n",
    "#         callbacks=[early_stopping],\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "#     results.append(val_accuracy)\n",
    "\n",
    "# print(f\"Mean Cross-Validation Accuracy: {np.mean(results)}\")\n",
    "\n",
    "# # Evaluate on the test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=50,\n",
    "#     batch_size=4,\n",
    "#     callbacks=[early_stopping],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[indices, 1:-1].values  # Features\n",
    "y = data.iloc[indices, -1].values    # Labels\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for transformer input\n",
    "X_normalized = X_normalized.reshape((X_normalized.shape[0], 1, X_normalized.shape[1]))  # (samples, 1, features)\n",
    "\n",
    "# Split the data into two parts: 80% training (part1) and 20% unseen (part2)\n",
    "X_part1, X_part2, y_part1, y_part2 = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "\n",
    "# Define a simple Transformer block\n",
    "def transformer_block(inputs, num_heads, ff_dim):\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tf.keras.layers.Add()([x, inputs])\n",
    "    x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(inputs.shape[-1])(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tf.keras.layers.Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "# Build the transformer model\n",
    "input_layer = Input(shape=(X_part1.shape[1], X_part1.shape[2]))\n",
    "x = transformer_block(input_layer, num_heads=2, ff_dim=64)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Cross-validation setup on the first part of the data\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "fold_accuracies = []\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_part1, y_part1)):\n",
    "    print(f\"Processing Fold {fold + 1}\")\n",
    "    X_train, X_val = X_part1[train_index], X_part1[val_index]\n",
    "    y_train, y_val = y_part1[train_index], y_part1[val_index]\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    accuracy = np.mean(y_pred == y_val)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"Cross-validation Accuracies:\", fold_accuracies)\n",
    "print(\"Mean Cross-validation Accuracy:\", np.mean(fold_accuracies))\n",
    "\n",
    "\n",
    "X_combined_reshaped = np.concatenate([X_part1, X_part2], axis=0)\n",
    "y_combined = np.concatenate([y_part1, y_part2], axis=0)\n",
    "model.fit(X_combined_reshaped, y_combined, epochs=50, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the final model on the unseen part (X_part2)\n",
    "y_pred_final = (model.predict(X_part2) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on Unseen Data:\")\n",
    "print(classification_report(y_part2, y_pred_final))\n",
    "print(confusion_matrix(y_part2, y_pred_final))\n",
    "\n",
    "# Optionally, you can also split the entire data into 80:20 again and test on that split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_combined_reshaped, y_combined, test_size=0.2, random_state=42, stratify=y_combined)\n",
    "y_pred_test_full = (model.predict(X_test_full) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on 20% Test Split:\")\n",
    "print(classification_report(y_test_full, y_pred_test_full))\n",
    "print(confusion_matrix(y_test_full, y_pred_test_full))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abeb55",
   "metadata": {},
   "source": [
    "# cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37896b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 264ms/step - loss: 1.7275 - accuracy: 0.3333 - val_loss: 0.5952 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0729 - accuracy: 0.4167 - val_loss: 0.6789 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5850 - accuracy: 0.5833 - val_loss: 1.3883 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3546 - accuracy: 0.7917 - val_loss: 1.6314 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6765 - accuracy: 0.6250 - val_loss: 1.3587 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4392 - accuracy: 0.8333 - val_loss: 0.9049 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.7287 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2665 - accuracy: 0.9583 - val_loss: 0.7284 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2944 - accuracy: 0.9583 - val_loss: 0.8197 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1696 - accuracy: 0.9583 - val_loss: 1.2720 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1199 - accuracy: 0.9583 - val_loss: 1.1010 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0852 - accuracy: 0.9583 - val_loss: 0.6797 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.9116 - val_accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0107 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.5281 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8089 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.9229 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1880 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.9468 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8396 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7363 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7092 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8835 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.0881 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3044 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 2.7772 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.5653 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.0476 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.3107 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 4.2330 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.9922 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7375 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.4714 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.2850 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.1318 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0059 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.1375e-04 - accuracy: 1.0000 - val_loss: 2.8741 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7263 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5823 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4528 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3924 - val_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6807 - accuracy: 0.6250\n",
      "Test Accuracy: 62.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.75      0.60      0.67         5\n",
      "         MDD       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.62      0.63      0.62         8\n",
      "weighted avg       0.66      0.62      0.63         8\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "#0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "# Separate features and labels\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "X = data.iloc[indices,1:-1]\n",
    "y = data.iloc[indices, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2,  verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8e348b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.9813 - accuracy: 0.7000 - val_loss: 0.7643 - val_accuracy: 0.3750\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.9121 - accuracy: 0.6000 - val_loss: 0.7805 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4582 - accuracy: 0.7667 - val_loss: 0.9613 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2192 - accuracy: 0.9333 - val_loss: 0.8514 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2205 - accuracy: 0.9333 - val_loss: 0.8553 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1714 - accuracy: 0.9333 - val_loss: 0.9137 - val_accuracy: 0.6250\n",
      "Validation Report for Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.42      0.43      0.37         8\n",
      "weighted avg       0.44      0.38      0.35         8\n",
      "\n",
      "[[1 4]\n",
      " [1 2]]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 102ms/step - loss: 1.6681 - accuracy: 0.6667 - val_loss: 2.5117 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.3072 - accuracy: 0.4667 - val_loss: 0.4349 - val_accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5130 - accuracy: 0.7667 - val_loss: 0.4470 - val_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4112 - accuracy: 0.8333 - val_loss: 0.4483 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2647 - accuracy: 0.9000 - val_loss: 0.4662 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1970 - accuracy: 0.9667 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0954 - accuracy: 0.9667 - val_loss: 0.3812 - val_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.6983 - val_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0665 - accuracy: 0.9667 - val_loss: 0.7409 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0553 - accuracy: 0.9667 - val_loss: 1.0584 - val_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0708 - accuracy: 0.9667 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.7500\n",
      "Validation Report for Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.67      0.86      0.67         8\n",
      "weighted avg       0.92      0.75      0.79         8\n",
      "\n",
      "[[1 0]\n",
      " [2 5]]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 2.1082 - accuracy: 0.5333 - val_loss: 0.6386 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8314 - accuracy: 0.5333 - val_loss: 0.9209 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4447 - accuracy: 0.7667 - val_loss: 1.0423 - val_accuracy: 0.6250\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3922 - accuracy: 0.9000 - val_loss: 1.0155 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1795 - accuracy: 0.9333 - val_loss: 0.7885 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.7500\n",
      "Validation Report for Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50         3\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.53      0.53      0.50         8\n",
      "weighted avg       0.57      0.50      0.50         8\n",
      "\n",
      "[[2 1]\n",
      " [3 2]]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 1.7311 - accuracy: 0.6774 - val_loss: 1.4523 - val_accuracy: 0.4286\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.6991 - accuracy: 0.6452 - val_loss: 0.7339 - val_accuracy: 0.4286\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7009 - accuracy: 0.5161 - val_loss: 0.6808 - val_accuracy: 0.4286\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6022 - accuracy: 0.6452 - val_loss: 0.6644 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4753 - accuracy: 0.8065 - val_loss: 0.6885 - val_accuracy: 0.4286\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.4002 - accuracy: 0.7742 - val_loss: 0.8894 - val_accuracy: 0.4286\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2968 - accuracy: 0.8710 - val_loss: 0.9474 - val_accuracy: 0.4286\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1813 - accuracy: 0.9677 - val_loss: 0.8741 - val_accuracy: 0.5714\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2008 - accuracy: 0.9032 - val_loss: 0.9777 - val_accuracy: 0.5714\n",
      "Validation Report for Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.75      0.62      0.53         7\n",
      "weighted avg       0.79      0.57      0.51         7\n",
      "\n",
      "[[1 3]\n",
      " [0 3]]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 299ms/step - loss: 2.3194 - accuracy: 0.5806 - val_loss: 1.2249 - val_accuracy: 0.5714\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.9718 - accuracy: 0.7419 - val_loss: 0.4033 - val_accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4842 - accuracy: 0.7419 - val_loss: 0.3010 - val_accuracy: 0.8571\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7203 - accuracy: 0.6129 - val_loss: 0.3396 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.4106 - accuracy: 0.8710 - val_loss: 0.6950 - val_accuracy: 0.7143\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2764 - accuracy: 0.9032 - val_loss: 1.1095 - val_accuracy: 0.7143\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.2625 - accuracy: 0.9032 - val_loss: 0.8933 - val_accuracy: 0.7143\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.9302 - val_accuracy: 0.7143\n",
      "Validation Report for Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.43      0.50      0.46         7\n",
      "weighted avg       0.73      0.86      0.79         7\n",
      "\n",
      "[[0 1]\n",
      " [0 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5149 - accuracy: 0.5263WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 35ms/step - loss: 1.5149 - accuracy: 0.5263\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7368WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5229 - accuracy: 0.7368\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.6579WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.6280 - accuracy: 0.6579\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.8158WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4607 - accuracy: 0.8158\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8158WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3229 - accuracy: 0.8158\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2485 - accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.1616 - accuracy: 0.9474\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.1156 - accuracy: 0.9474\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1034 - accuracy: 0.9474\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.1392 - accuracy: 0.9737\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0676 - accuracy: 0.9737\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0582 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0735 - accuracy: 0.9737\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0442 - accuracy: 0.9737\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0847 - accuracy: 0.9737\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0891 - accuracy: 0.9737\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0229 - accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9737  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0402 - accuracy: 0.9737\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0142 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0227 - accuracy: 0.9737\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.6168e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6168e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0221 - accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9737  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0563 - accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0680 - accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9474  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0689 - accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Final Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         7\n",
      "   macro avg       1.00      1.00      1.00         7\n",
      "weighted avg       1.00      1.00      1.00         7\n",
      "\n",
      "[[1 0]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "print(data.iloc[1,0])\n",
    "\n",
    "# Separate features and labels\n",
    "indices = list(range(38))  # Include all rows\n",
    "X = data.iloc[indices, 1:-1].values  # Features\n",
    "y = data.iloc[indices, -1].values    # Labels\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for CNN input: (samples, height, width, channels)\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (1, 10), activation='relu', input_shape=(1, X_scaled.shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Conv2D(64, (1, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "for train_index, val_index in kf.split(X_reshaped):\n",
    "    X_train, X_val = X_reshaped[train_index], X_reshaped[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_cnn_model()\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    print(\"Validation Report for Fold:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "final_model = create_cnn_model()\n",
    "final_model.fit(X_reshaped, y_encoded, epochs=50, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "# Optionally, evaluate the final model on a separate test set if available\n",
    "# For demonstration purposes, we can use the validation data from the last fold\n",
    "X_test, y_test = X_val, y_val\n",
    "y_pred_final = (final_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(confusion_matrix(y_test, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99896336",
   "metadata": {},
   "source": [
    "# making 20% unseen data and training on rest to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffd6012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Processing Fold 1\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 92ms/step - loss: 0.8547 - accuracy: 0.5000 - val_loss: 0.8056 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0731 - accuracy: 0.6250 - val_loss: 0.8895 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3865 - accuracy: 0.7083 - val_loss: 0.4307 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6096 - accuracy: 0.5833 - val_loss: 0.8970 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8868 - accuracy: 0.6250 - val_loss: 0.8975 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3239 - accuracy: 0.8333 - val_loss: 0.6542 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3427 - accuracy: 0.7917 - val_loss: 0.7265 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4523 - accuracy: 0.7500 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Fold 1 Accuracy: 0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "[[4 0]\n",
      " [0 2]]\n",
      "Processing Fold 2\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 99ms/step - loss: 1.8171 - accuracy: 0.4583 - val_loss: 2.0338 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.6134 - accuracy: 0.5833 - val_loss: 1.2563 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5679 - accuracy: 0.7917 - val_loss: 3.6888 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4770 - accuracy: 0.7917 - val_loss: 2.8797 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2915 - accuracy: 0.8750 - val_loss: 0.9531 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1113 - accuracy: 0.9583 - val_loss: 1.0908 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0943 - accuracy: 0.9583 - val_loss: 1.2458 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 1.3598 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 1.5420 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.5000\n",
      "Fold 2 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57         4\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.50      0.49         6\n",
      "weighted avg       0.56      0.50      0.51         6\n",
      "\n",
      "[[2 2]\n",
      " [1 1]]\n",
      "Processing Fold 3\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 105ms/step - loss: 2.8887 - accuracy: 0.4583 - val_loss: 1.7544 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.7886 - accuracy: 0.5000 - val_loss: 3.1495 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2001 - accuracy: 0.6250 - val_loss: 2.2819 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3539 - accuracy: 0.9167 - val_loss: 2.8225 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8925 - accuracy: 0.7500 - val_loss: 2.9129 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2274 - accuracy: 0.9167 - val_loss: 2.6155 - val_accuracy: 0.3333\n",
      "Fold 3 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "Processing Fold 4\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 98ms/step - loss: 0.8685 - accuracy: 0.5833 - val_loss: 1.6645 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.6442 - accuracy: 0.5833 - val_loss: 0.6461 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0307 - accuracy: 0.6250 - val_loss: 0.5021 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5820 - accuracy: 0.7083 - val_loss: 1.7798 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6799 - accuracy: 0.6667 - val_loss: 1.3860 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2775 - accuracy: 0.8750 - val_loss: 0.5381 - val_accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1535 - accuracy: 0.9167 - val_loss: 0.4188 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1063 - accuracy: 0.9583 - val_loss: 0.4553 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1251 - accuracy: 0.9583 - val_loss: 0.5091 - val_accuracy: 0.8333\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0926 - accuracy: 0.9583 - val_loss: 0.7077 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1648 - accuracy: 0.9167 - val_loss: 0.6807 - val_accuracy: 0.6667\n",
      "Fold 4 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.67      0.67      0.67         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "[[2 1]\n",
      " [1 2]]\n",
      "Processing Fold 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 101ms/step - loss: 0.6718 - accuracy: 0.5833 - val_loss: 2.0130 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1656 - accuracy: 0.7083 - val_loss: 4.0811 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3838 - accuracy: 0.8333 - val_loss: 2.1996 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3868 - accuracy: 0.7917 - val_loss: 1.8243 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0626 - accuracy: 0.9583 - val_loss: 2.6081 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1634 - accuracy: 0.8750 - val_loss: 2.2093 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1746 - accuracy: 0.9167 - val_loss: 1.5575 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 2.1041 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 2.3431 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0992 - accuracy: 0.9583 - val_loss: 2.1335 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.7662 - val_accuracy: 0.5000\n",
      "Fold 5 Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.25      0.50      0.33         6\n",
      "weighted avg       0.25      0.50      0.33         6\n",
      "\n",
      "[[3 0]\n",
      " [3 0]]\n",
      "Cross-validation Accuracies: [0.5555555555555556, 0.5, 0.5, 0.5, 0.5]\n",
      "Mean Cross-validation Accuracy: 0.5111111111111111\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\stuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 4s - loss: 0.9000 - accuracy: 0.5000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 1s 11ms/step - loss: 5.6227 - accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8593 - accuracy: 0.6250WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9759 - accuracy: 0.5789\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2233 - accuracy: 0.7368WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2233 - accuracy: 0.7368\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.7368WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8194 - accuracy: 0.7368\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8421WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3240 - accuracy: 0.8421\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4008 - accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1536 - accuracy: 0.9474\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1248 - accuracy: 0.9737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1197 - accuracy: 0.9737\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1178 - accuracy: 0.9737\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0674 - accuracy: 0.9737\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0615 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0263 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0399 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0729 - accuracy: 0.9737\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0611 - accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0425 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0735 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1162 - accuracy: 0.9737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0373 - accuracy: 0.9737\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0418 - accuracy: 0.9737\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0740 - accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8385e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7038e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Final Model Evaluation on Unseen Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n",
      "Final Model Evaluation on 20% Test Split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[4 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[indices, 1:-1].values  # Features\n",
    "y = data.iloc[indices, -1].values    # Labels\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Split the data into two parts: 80% training (part1) and 20% unseen (part2)\n",
    "X_part1, X_part2, y_part1, y_part2 = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_part1_scaled = scaler.fit_transform(X_part1)\n",
    "X_part2_scaled = scaler.transform(X_part2)\n",
    "\n",
    "# Reshape for CNN input: (samples, height, width, channels)\n",
    "X_part1_reshaped = X_part1_scaled.reshape(X_part1_scaled.shape[0], 1, X_part1_scaled.shape[1], 1)\n",
    "X_part2_reshaped = X_part2_scaled.reshape(X_part2_scaled.shape[0], 1, X_part2_scaled.shape[1], 1)\n",
    "\n",
    "# Define a CNN model\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (1, 5), activation='relu', input_shape=(1, X_part1_scaled.shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cross-validation setup on the first part of the data\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "fold_accuracies = []\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_part1_reshaped, y_part1)):\n",
    "    print(f\"Processing Fold {fold + 1}\")\n",
    "    X_train, X_val = X_part1_reshaped[train_index], X_part1_reshaped[val_index]\n",
    "    y_train, y_val = y_part1[train_index], y_part1[val_index]\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_cnn_model()\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    accuracy = np.mean(y_pred == y_val)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"Cross-validation Accuracies:\", fold_accuracies)\n",
    "print(\"Mean Cross-validation Accuracy:\", np.mean(fold_accuracies))\n",
    "\n",
    "# Train the final model on the entire dataset (X_part1 + X_part2)\n",
    "final_model = create_cnn_model()\n",
    "X_combined_reshaped = np.concatenate([X_part1_reshaped, X_part2_reshaped], axis=0)\n",
    "y_combined = np.concatenate([y_part1, y_part2], axis=0)\n",
    "final_model.fit(X_combined_reshaped, y_combined, epochs=50, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the final model on the unseen part (X_part2)\n",
    "y_pred_final = (final_model.predict(X_part2_reshaped) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on Unseen Data:\")\n",
    "print(classification_report(y_part2, y_pred_final))\n",
    "print(confusion_matrix(y_part2, y_pred_final))\n",
    "\n",
    "# Optionally, you can also split the entire data into 80:20 again and test on that split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_combined_reshaped, y_combined, test_size=0.2, random_state=42, stratify=y_combined)\n",
    "y_pred_test_full = (final_model.predict(X_test_full) > 0.5).astype(\"int32\")\n",
    "print(\"Final Model Evaluation on 20% Test Split:\")\n",
    "print(classification_report(y_test_full, y_pred_test_full))\n",
    "print(confusion_matrix(y_test_full, y_pred_test_full))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6576e",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e57be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "sub-002\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "[0 0 1 1 0 0 1 0]\n",
      "[[3 2]\n",
      " [2 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.47      0.47      0.47         8\n",
      "weighted avg       0.50      0.50      0.50         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "# print(data.shape)\n",
    "# print(data.iloc[1,0])\n",
    "# indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "# print(len(indices))\n",
    "# # Separate features and labels\n",
    "# X = data.iloc[indices,1:-1]\n",
    "# y = data.iloc[indices, -1]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# # Encode labels (MDD -> 1, HC -> 0)\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Initialize and train the model\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(y_test)\n",
    "# # Evaluate the model\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a32df",
   "metadata": {},
   "source": [
    "# with stratified k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a09ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Best Score: 0.5666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.43      0.75      0.55         4\n",
      "         MDD       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.21      0.38      0.27         8\n",
      "weighted avg       0.21      0.38      0.27         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [4 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "# Separate features and labels\n",
    "X = data.iloc[indices, 1:-1]  # Features\n",
    "y = data.iloc[indices, -1]    # Labels\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Encode labels (MDD -> 1, HC -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# # Initial 80:20 split of the entire dataset\n",
    "# X_train_full, X_unseen, y_train_full, y_unseen = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Apply stratified k-fold cross-validation on the first 80%\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_full = scaler.fit_transform(X_train_full)\n",
    "# X_unseen = scaler.transform(X_unseen)\n",
    "\n",
    "# # Cross-validation and training on the 80% data\n",
    "# for fold, (train_index, val_index) in enumerate(kf.split(X_train_full, y_train_full)):\n",
    "#     print(f\"Processing Fold {fold + 1}\")\n",
    "#     X_train, X_val = X_train_full[train_index], X_train_full[val_index]\n",
    "#     y_train, y_val = y_train_full[train_index], y_train_full[val_index]\n",
    "    \n",
    "#     # Initialize and train the model\n",
    "#     model = RandomForestClassifier(random_state=42)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions on validation set\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "    \n",
    "#     # Evaluate the model on validation set\n",
    "#     print(f\"Validation Report for Fold {fold + 1}:\")\n",
    "#     print(confusion_matrix(y_val, y_val_pred))\n",
    "#     print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# # After cross-validation, train the model on the entire 80% dataset\n",
    "# model_final = RandomForestClassifier(random_state=42)\n",
    "# model_final.fit(X, y)\n",
    "\n",
    "# # Evaluate the final model on the unseen 20% data\n",
    "# y_unseen_pred = (model.predict(X_unseen)>0.5).astype(\"int32\")\n",
    "# print(\"Final Model Evaluation on Unseen Data:\")\n",
    "# print(confusion_matrix(y_unseen, y_unseen_pred))\n",
    "# print(classification_report(y_unseen, y_unseen_pred))\n",
    "\n",
    "# # Optionally, you can also split the entire data into 80:20 again and test on that split\n",
    "# X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# y_pred_test_full = (model.predict(X_test_full) > 0.5).astype(\"int32\")\n",
    "# print(\"Final Model Evaluation on 20% Test Split:\")\n",
    "# print(classification_report(y_test_full, y_pred_test_full))\n",
    "# print(confusion_matrix(y_test_full, y_pred_test_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c511b8",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2d8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Initialize and train the model\n",
    "# logistic_model = LogisticRegression(random_state=42)\n",
    "# logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Logistic Regression\")\n",
    "# print(confusion_matrix(y_test, y_pred_logistic))\n",
    "# print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1732948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 1, 'penalty': 'l1'}\n",
      "Best Score: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.60      0.75      0.67         4\n",
      "         MDD       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize LogisticRegression\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_log_reg.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15908aa",
   "metadata": {},
   "source": [
    "# svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7ea5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initialize and train the model\n",
    "# svm_model = SVC(kernel='linear', random_state=42)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Support Vector Machine\")\n",
    "# print(confusion_matrix(y_test, y_pred_svm))\n",
    "# print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b919e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best Score: 0.6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.60      0.75      0.67         4\n",
      "         MDD       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize SVC\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']  # Only relevant for 'rbf' and 'poly' kernels\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_svc.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c30eb",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92dd48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"K-Nearest Neighbors\")\n",
    "# print(confusion_matrix(y_test, y_pred_knn))\n",
    "# print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb52a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best Score: 0.6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.57      1.00      0.73         4\n",
      "         MDD       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.79      0.62      0.56         8\n",
      "weighted avg       0.79      0.62      0.56         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 0]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa670556",
   "metadata": {},
   "source": [
    "# gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b3be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# gb_model = GradientBoostingClassifier(random_state=42)\n",
    "# gb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Gradient Boosting\")\n",
    "# print(confusion_matrix(y_test, y_pred_gb))\n",
    "# print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92bee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Best Score: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.40      0.50      0.44         4\n",
      "         MDD       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.37      0.38      0.37         8\n",
      "weighted avg       0.37      0.38      0.37         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 2]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_gbm = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_gbm.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f618178",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5fcef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# # Initialize and train the model\n",
    "# nb_model = GaussianNB()\n",
    "# nb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Naive Bayes\")\n",
    "# print(confusion_matrix(y_test, y_pred_nb))\n",
    "# print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57856a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.8333333333333334, 0.5, 0.16666666666666666, 0.16666666666666666, 0.6666666666666666]\n",
      "Mean cross-validation score: 0.4666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         4\n",
      "         MDD       0.20      0.25      0.22         4\n",
      "\n",
      "    accuracy                           0.12         8\n",
      "   macro avg       0.10      0.12      0.11         8\n",
      "weighted avg       0.10      0.12      0.11         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 4]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GaussianNB classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Note: GaussianNB doesn't have many hyperparameters to tune, so we'll fit it directly\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = []\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    gnb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Evaluate on the validation fold\n",
    "    score = gnb.score(X_val_fold, y_val_fold)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", sum(cv_scores) / len(cv_scores))\n",
    "\n",
    "# Train the final model on the full training set\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4a5fd",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fbdd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Decision Tree\")\n",
    "# print(confusion_matrix(y_test, y_pred_dt))\n",
    "# print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000a3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Score: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      0.75      0.86         4\n",
      "         MDD       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.90      0.88      0.87         8\n",
      "weighted avg       0.90      0.88      0.87         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25eb9b2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d50cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# xgb_model = XGBClassifier(random_state=42)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"XGBoost\")\n",
    "# print(confusion_matrix(y_test, y_pred_xgb))\n",
    "# print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ea3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Best Score: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.43      0.75      0.55         4\n",
      "         MDD       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.21      0.38      0.27         8\n",
      "weighted avg       0.21      0.38      0.27         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [4 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:45:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc08f39",
   "metadata": {},
   "source": [
    "## dot probe state HC vs MDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd814",
   "metadata": {},
   "source": [
    "# lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6748e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# #0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "\n",
    "\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "# print(data.shape)\n",
    "# print(data.iloc[1,0])\n",
    "# # Separate features and labels\n",
    "# indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "# print(len(indices))\n",
    "# X = data.iloc[indices,1:-1]\n",
    "# y = data.iloc[indices, -1]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "# #Encode the labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# print(\"shape after scaling\")\n",
    "# print(X_scaled.shape)\n",
    "# # Reshape data for LSTM (samples, timesteps, features)\n",
    "# # Assuming each sample is treated as a single timestep\n",
    "# X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "# print(\"shape after reshaping\")\n",
    "# print(X_reshaped.shape)\n",
    "# #Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # Build the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(32, return_sequences=False))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044d620",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75583aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# #0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "# print(data.shape)\n",
    "# print(data.iloc[1,0])\n",
    "# # Separate features and labels\n",
    "# indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "# print(len(indices))\n",
    "# X = data.iloc[indices,1:-1]\n",
    "# y = data.iloc[indices, -1]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "# # Encode the labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Reshape data for Transformer (samples, timesteps, features)\n",
    "# X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Build the Transformer model\n",
    "# def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "#     # Normalization and Attention\n",
    "#     x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "#     x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "#     res = x + inputs\n",
    "\n",
    "#     # Feed Forward Part\n",
    "#     x = LayerNormalization(epsilon=1e-6)(res)\n",
    "#     x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "#     x = Dense(inputs.shape[-1])(x)\n",
    "#     return x + res\n",
    "\n",
    "# input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# inputs = Input(shape=input_shape)\n",
    "# x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
    "# x = GlobalAveragePooling1D()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(20, activation=\"relu\")(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# model = Model(inputs, outputs)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956300aa",
   "metadata": {},
   "source": [
    "## cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a9e6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "# #0-9,11,14-17,22-25,27-31,33-38,40,42-48\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "# print(data.shape)\n",
    "# print(data.iloc[1,0])\n",
    "# # Separate features and labels\n",
    "# indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "# print(len(indices))\n",
    "# X = data.iloc[indices,1:-1]\n",
    "# y = data.iloc[indices, -1]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# # np.random.seed(42)\n",
    "# # tf.random.set_seed(42)\n",
    "# # random.seed(42)\n",
    "\n",
    "# # Encode the labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Reshape data for CNN (samples, timesteps, features)\n",
    "# X_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Build the CNN model\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2,  verbose=1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e3151",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef869c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "# print(data.shape)\n",
    "# print(data.iloc[1,0])\n",
    "# # Separate features and labels\n",
    "# X = data.iloc[indices,1:-1]\n",
    "# y = data.iloc[indices, -1]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# # Encode labels (MDD -> 1, HC -> 0)\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Initialize and train the model\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(y_test)\n",
    "# # Evaluate the model\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427a9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "38\n",
      "(38, 2688)\n",
      "(38,)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.6666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.75      0.75      0.75         4\n",
      "         MDD       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.75      0.75      0.75         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data.shape)\n",
    "indices=[0,1,2,3,4,5,6,7,8,9,11,14,15,16,17,22,23,24,25,27,28,29,30,31,33,34,35,36,37,38,40,42,43,44,45,46,47,48]\n",
    "print(len(indices))\n",
    "# Separate features and labels\n",
    "X = data.iloc[indices, 1:-1]  # Features\n",
    "y = data.iloc[indices, -1]    # Labels\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Encode labels (MDD -> 1, HC -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# # Initial 80:20 split of the entire dataset\n",
    "# X_train_full, X_unseen, y_train_full, y_unseen = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Apply stratified k-fold cross-validation on the first 80%\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_full = scaler.fit_transform(X_train_full)\n",
    "# X_unseen = scaler.transform(X_unseen)\n",
    "\n",
    "# # Cross-validation and training on the 80% data\n",
    "# for fold, (train_index, val_index) in enumerate(kf.split(X_train_full, y_train_full)):\n",
    "#     print(f\"Processing Fold {fold + 1}\")\n",
    "#     X_train, X_val = X_train_full[train_index], X_train_full[val_index]\n",
    "#     y_train, y_val = y_train_full[train_index], y_train_full[val_index]\n",
    "    \n",
    "#     # Initialize and train the model\n",
    "#     model = RandomForestClassifier(random_state=42)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions on validation set\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "    \n",
    "#     # Evaluate the model on validation set\n",
    "#     print(f\"Validation Report for Fold {fold + 1}:\")\n",
    "#     print(confusion_matrix(y_val, y_val_pred))\n",
    "#     print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# # After cross-validation, train the model on the entire 80% dataset\n",
    "# model_final = RandomForestClassifier(random_state=42)\n",
    "# model_final.fit(X, y)\n",
    "\n",
    "# # Evaluate the final model on the unseen 20% data\n",
    "# y_unseen_pred = (model.predict(X_unseen)>0.5).astype(\"int32\")\n",
    "# print(\"Final Model Evaluation on Unseen Data:\")\n",
    "# print(confusion_matrix(y_unseen, y_unseen_pred))\n",
    "# print(classification_report(y_unseen, y_unseen_pred))\n",
    "\n",
    "# # Optionally, you can also split the entire data into 80:20 again and test on that split\n",
    "# X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# y_pred_test_full = (model.predict(X_test_full) > 0.5).astype(\"int32\")\n",
    "# print(\"Final Model Evaluation on 20% Test Split:\")\n",
    "# print(classification_report(y_test_full, y_pred_test_full))\n",
    "# print(confusion_matrix(y_test_full, y_pred_test_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183691e",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfc8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Initialize and train the model\n",
    "# logistic_model = LogisticRegression(random_state=42)\n",
    "# logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Logistic Regression\")\n",
    "# print(confusion_matrix(y_test, y_pred_logistic))\n",
    "# print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9819c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.001, 'penalty': 'l2'}\n",
      "Best Score: 0.6666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      0.50      0.57         4\n",
      "         MDD       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize LogisticRegression\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_log_reg.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9bddd",
   "metadata": {},
   "source": [
    "## svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e580d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initialize and train the model\n",
    "# svm_model = SVC(kernel='linear', random_state=42)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Support Vector Machine\")\n",
    "# print(confusion_matrix(y_test, y_pred_svm))\n",
    "# print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a217a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Best Score: 0.6333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.57      1.00      0.73         4\n",
      "         MDD       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.79      0.62      0.56         8\n",
      "weighted avg       0.79      0.62      0.56         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 0]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize SVC\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']  # Only relevant for 'rbf' and 'poly' kernels\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_svc.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98577ee3",
   "metadata": {},
   "source": [
    "# k neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c927c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"K-Nearest Neighbors\")\n",
    "# print(confusion_matrix(y_test, y_pred_knn))\n",
    "# print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e4d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best Score: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.60      0.75      0.67         4\n",
      "         MDD       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5ad14",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce772543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# gb_model = GradientBoostingClassifier(random_state=42)\n",
    "# gb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Gradient Boosting\")\n",
    "# print(confusion_matrix(y_test, y_pred_gb))\n",
    "# print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fe7850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Score: 0.6333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      0.50      0.67         4\n",
      "         MDD       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.83      0.75      0.73         8\n",
      "weighted avg       0.83      0.75      0.73         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 2]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_gbm = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_gbm.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429687f",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d608da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# # Initialize and train the model\n",
    "# nb_model = GaussianNB()\n",
    "# nb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Naive Bayes\")\n",
    "# print(confusion_matrix(y_test, y_pred_nb))\n",
    "# print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c95fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
      "Mean cross-validation score: 0.6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.60      0.75      0.67         4\n",
      "         MDD       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GaussianNB classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Note: GaussianNB doesn't have many hyperparameters to tune, so we'll fit it directly\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = []\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    gnb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Evaluate on the validation fold\n",
    "    score = gnb.score(X_val_fold, y_val_fold)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", sum(cv_scores) / len(cv_scores))\n",
    "\n",
    "# Train the final model on the full training set\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01479852",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee910db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Decision Tree\")\n",
    "# print(confusion_matrix(y_test, y_pred_dt))\n",
    "# print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81df337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Score: 0.6333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      0.50      0.57         4\n",
      "         MDD       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32aa588",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8425c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize and train the model\n",
    "# xgb_model = XGBClassifier(random_state=42)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"XGBoost\")\n",
    "# print(confusion_matrix(y_test, y_pred_xgb))\n",
    "# print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca771fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:11:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Best Score: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.75      0.75      0.75         4\n",
      "         MDD       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.75      0.75      0.75         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdd26c",
   "metadata": {},
   "source": [
    "## resting state HC vs Task State HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8a6a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices\n",
    "# 0-23 ---MDD\n",
    "#24-52 ----HC\n",
    "indices_MDD=[0,\n",
    " 1,\n",
    " 2,\n",
    " 3,\n",
    " 4,\n",
    " 5,\n",
    " 6,\n",
    " 7,\n",
    " 8,\n",
    " 9,\n",
    " 11,\n",
    " 14,\n",
    " 15,\n",
    " 16,\n",
    " 17,\n",
    " 22,\n",
    " 23]\n",
    "indices_HC=[24,\n",
    " 25,\n",
    " 27,\n",
    " 28,\n",
    " 29,\n",
    " 30,\n",
    " 31,\n",
    " 33,\n",
    " 34,\n",
    " 35,\n",
    " 36,\n",
    " 37,\n",
    " 38,\n",
    " 40,\n",
    " 42,\n",
    " 43,\n",
    " 44,\n",
    " 45,\n",
    " 46,\n",
    " 47,\n",
    " 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c001c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cebca0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_MDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28c0c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(21, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_ts = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data_ts.shape)\n",
    "data_ts_HC=data_ts.iloc[indices_HC,1:-1]\n",
    "#data_ts_HC_labels=data_ts.iloc[24:,-1]\n",
    "print(data_ts_HC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "207617d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(21, 2688)\n"
     ]
    }
   ],
   "source": [
    "data_rs = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data_rs.shape)\n",
    "data_rs_HC=data_rs.iloc[indices_HC,1:-1]\n",
    "#data_rs_HC_labels=data_rs.iloc[24:,-1]\n",
    "print(data_rs_HC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19091999",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rs_HC_labels=np.zeros(data_rs_HC.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e495c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_rs_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11526008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_ts_HC_labels=np.ones(data_ts_HC.shape[0])\n",
    "print(data_ts_HC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "897976b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 2688)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features=np.concatenate((data_rs_HC,data_ts_HC),axis=0)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "258c9fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels=np.concatenate((data_rs_HC_labels,data_ts_HC_labels),axis=0)\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68732b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_features\n",
    "y=all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71cdd50",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08ab022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 2688)\n",
      "(42,)\n",
      "shape after scaling\n",
      "(42, 2688)\n",
      "shape after reshaping\n",
      "(42, 1, 2688)\n",
      "[0 0 0 0 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 1 1 1]\n",
      "[0 0 0 0 1 1 1 1]\n",
      "[0 0 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 1 1 1]\n",
      "Average Accuracy: 95.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.91      1.00      0.95        21\n",
      "         MDD       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.96      0.95      0.95        42\n",
      "weighted avg       0.96      0.95      0.95        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"shape after scaling\")\n",
    "print(X_scaled.shape)\n",
    "\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "print(\"shape after reshaping\")\n",
    "print(X_reshaped.shape)\n",
    "#Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define number of splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to hold results\n",
    "accuracy_list = []\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    print(y_test)\n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Predict and store results\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_true_list.extend(y_test)\n",
    "    y_pred_list.extend(y_pred)\n",
    "\n",
    "# Print average accuracy\n",
    "print(f'Average Accuracy: {np.mean(accuracy_list) * 100:.2f}%')\n",
    "\n",
    "# Print the classification report for all folds\n",
    "print(classification_report(y_true_list, y_pred_list, target_names=['HC', 'MDD']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Build the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(32, return_sequences=False))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa17986",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbd4e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 90.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.90      0.90      0.90        21\n",
      "         MDD       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.90      0.90      0.90        42\n",
      "weighted avg       0.90      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, MultiHeadAttention, Flatten, Add, LayerNormalization\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for Transformer (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Build the Transformer model\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list = []\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    \n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(20, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Predict and store results\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_true_list.extend(y_test)\n",
    "    y_pred_list.extend(y_pred)\n",
    "\n",
    "# Print average accuracy\n",
    "print(f'Average Accuracy: {np.mean(accuracy_list) * 100:.2f}%')\n",
    "\n",
    "# Print the classification report for all folds\n",
    "print(classification_report(y_true_list, y_pred_list, target_names=['HC', 'MDD']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "456058a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# # Encode the labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Reshape data for Transformer (samples, timesteps, features)\n",
    "# X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Build the Transformer model\n",
    "# def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "#     # Normalization and Attention\n",
    "#     x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "#     x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "#     res = x + inputs\n",
    "\n",
    "#     # Feed Forward Part\n",
    "#     x = LayerNormalization(epsilon=1e-6)(res)\n",
    "#     x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "#     x = Dense(inputs.shape[-1])(x)\n",
    "#     return x + res\n",
    "\n",
    "# input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# inputs = Input(shape=input_shape)\n",
    "# x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
    "# x = GlobalAveragePooling1D()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(20, activation=\"relu\")(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# model = Model(inputs, outputs)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Predict the labels for the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy/Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training History')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbbbe5",
   "metadata": {},
   "source": [
    "## cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a489d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 1.4530 - accuracy: 0.4615 - val_loss: 0.4798 - val_accuracy: 0.5714\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8150 - accuracy: 0.5769 - val_loss: 0.3434 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6963 - accuracy: 0.6923 - val_loss: 0.3686 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.3692 - accuracy: 0.8462 - val_loss: 0.1965 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2653 - accuracy: 0.8846 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.1654 - accuracy: 0.9615 - val_loss: 0.0894 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.0057e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 8.6496e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 4.0900e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 5.6581e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.4788e-04 - accuracy: 1.0000 - val_loss: 9.2105e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.8434e-04 - accuracy: 1.0000 - val_loss: 6.7477e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.6655e-04 - accuracy: 1.0000 - val_loss: 5.3836e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.6461e-04 - accuracy: 1.0000 - val_loss: 4.5966e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.6660e-04 - accuracy: 1.0000 - val_loss: 4.0616e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.5495e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.8352e-04 - accuracy: 1.0000 - val_loss: 3.1911e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 3.8440e-05 - accuracy: 1.0000 - val_loss: 2.9341e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7532e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9888e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.5419e-04 - accuracy: 1.0000 - val_loss: 3.3835e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3557e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.4456e-04 - accuracy: 1.0000 - val_loss: 3.0730e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.5592e-04 - accuracy: 1.0000 - val_loss: 2.6999e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.4375e-04 - accuracy: 1.0000 - val_loss: 2.3336e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.4842e-04 - accuracy: 1.0000 - val_loss: 2.0964e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 4.9298e-04 - accuracy: 1.0000 - val_loss: 2.0650e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.7794e-04 - accuracy: 1.0000 - val_loss: 2.4346e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.6647e-04 - accuracy: 1.0000 - val_loss: 2.7423e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.7624e-04 - accuracy: 1.0000 - val_loss: 3.0420e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.8918e-04 - accuracy: 1.0000 - val_loss: 3.4212e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.8015e-04 - accuracy: 1.0000 - val_loss: 3.6501e-04 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6620e-04 - accuracy: 1.0000\n",
      "Test Accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      1.00      1.00         4\n",
      "         MDD       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20b6f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 85.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.83      0.90      0.86        21\n",
      "         MDD       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.86      0.86      0.86        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN (samples, timesteps, features)\n",
    "# Assuming each sample is treated as a single timestep\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# Define number of splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to hold results\n",
    "accuracy_list = []\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Build and compile the CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Predict and store results\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_true_list.extend(y_test)\n",
    "    y_pred_list.extend(y_pred)\n",
    "\n",
    "# Print average accuracy\n",
    "print(f'Average Accuracy: {np.mean(accuracy_list) * 100:.2f}%')\n",
    "\n",
    "# Print the classification report for all folds\n",
    "print(classification_report(y_true_list, y_pred_list, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Optional: Plot training history for the last fold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History (Last Fold)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968a715",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe3820c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Initialize and train the model\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(y_test)\n",
    "# # Evaluate the model\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c61e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.55555556 1.         1.         1.         1.        ]\n",
      "Mean accuracy: 0.9111111111111111\n",
      "Standard deviation: 0.17777777777777776\n",
      "[[18  3]\n",
      " [ 1 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.95      0.86      0.90        21\n",
      "         MDD       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.91      0.90      0.90        42\n",
      "weighted avg       0.91      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X_scaled, y_encoded, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f'Cross-validated scores: {scores}')\n",
    "print(f'Mean accuracy: {scores.mean()}')\n",
    "print(f'Standard deviation: {scores.std()}')\n",
    "\n",
    "# Cross-validation predictions and evaluation\n",
    "y_pred_all = []\n",
    "y_test_all = []\n",
    "\n",
    "for train_index, test_index in cv.split(X_scaled, y_encoded):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_test_all.extend(y_test)\n",
    "\n",
    "# Print confusion matrix and classification report for cross-validation\n",
    "print(confusion_matrix(y_test_all, y_pred_all))\n",
    "print(classification_report(y_test_all, y_pred_all, target_names=['HC', 'MDD']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372b268",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49a42e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94913efc",
   "metadata": {},
   "source": [
    "# svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a75e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bd476",
   "metadata": {},
   "source": [
    "# k neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a458feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b37dc2",
   "metadata": {},
   "source": [
    "# gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e193593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "[[3 1]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86         4\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.92      0.88      0.88         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52529a85",
   "metadata": {},
   "source": [
    "# gaussian nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6244643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[4 0]\n",
      " [1 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89         4\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.90      0.90      0.89         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948ffed",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c497d84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[2 2]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         4\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.86      0.75      0.75         9\n",
      "weighted avg       0.84      0.78      0.76         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03315d78",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d7a5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1762b1",
   "metadata": {},
   "source": [
    "## resting state MDD vs task state MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb6fca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(17, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_ts = pd.read_excel('dot_probe_HC_and_MDD.xlsx')\n",
    "print(data_ts.shape)\n",
    "data_ts_MDD=data_ts.iloc[indices_MDD,1:-1]\n",
    "#data_ts_HC_labels=data_ts.iloc[24:,-1]\n",
    "print(data_ts_MDD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99c5bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2690)\n",
      "(17, 2688)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_rs = pd.read_excel('resting_state_HC_and_MDD.xlsx')\n",
    "print(data_rs.shape)\n",
    "data_rs_MDD=data_rs.iloc[indices_MDD,1:-1]\n",
    "#data_rs_HC_labels=data_rs.iloc[24:,-1]\n",
    "print(data_rs_MDD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55b878e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_ts_MDD_labels=np.ones(data_ts_MDD.shape[0])\n",
    "print(data_ts_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11adc815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "data_rs_MDD_labels=np.zeros(data_rs_MDD.shape[0])\n",
    "print(data_rs_MDD_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62012321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 2688)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features=np.concatenate((data_rs_MDD,data_ts_MDD),axis=0)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ff42073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels=np.concatenate((data_rs_MDD_labels,data_ts_MDD_labels),axis=0)\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e886250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_features\n",
    "y=all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ab97d",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fc8c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 2688)\n",
      "(34,)\n",
      "shape after scaling\n",
      "(34, 2688)\n",
      "shape after reshaping\n",
      "(34, 1, 2688)\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.6951 - accuracy: 0.5238 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6001 - accuracy: 0.9048 - val_loss: 0.6091 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5374 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5436 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4881 - accuracy: 0.9524 - val_loss: 0.5023 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4652 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4636 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4376 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3938 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3746 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3724 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3561 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3387 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3005 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2846 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3106 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2439 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2458 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1947 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1821 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1985 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1818 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1830 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1504 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1776 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1590 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1264 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0909 - accuracy: 1.0000\n",
      "Test Accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      1.00      1.00         2\n",
      "         MDD       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         7\n",
      "   macro avg       1.00      1.00      1.00         7\n",
      "weighted avg       1.00      1.00      1.00         7\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"shape after scaling\")\n",
    "print(X_scaled.shape)\n",
    "\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "print(\"shape after reshaping\")\n",
    "print(X_reshaped.shape)\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3cae95",
   "metadata": {},
   "source": [
    "# TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d182968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 445ms/step - loss: 0.9351 - accuracy: 0.6190 - val_loss: 0.6134 - val_accuracy: 0.8333\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7759e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 8.5494e-11 - accuracy: 1.0000 - val_loss: 4.3375e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.0040e-11 - accuracy: 1.0000 - val_loss: 9.1189e-11 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0815 - accuracy: 0.9524 - val_loss: 7.0546 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.8320 - accuracy: 0.9048 - val_loss: 1.3264e-14 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 4.4478e-24 - accuracy: 1.0000 - val_loss: 2.4810 - val_accuracy: 0.8333\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.2616e-06 - accuracy: 1.0000 - val_loss: 6.8374 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 13.4936 - accuracy: 0.9524 - val_loss: 8.0300 - val_accuracy: 0.8333\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 3.3885 - accuracy: 0.9524 - val_loss: 6.7732 - val_accuracy: 0.8333\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 5.9015 - accuracy: 0.9524 - val_loss: 1.8623 - val_accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.0585 - accuracy: 0.8571\n",
      "Test Accuracy: 85.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      1.00      0.80         2\n",
      "         MDD       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.83      0.90      0.84         7\n",
      "weighted avg       0.90      0.86      0.86         7\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for Transformer (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Transformer model\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2404ad1",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "caa3434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.8556 - accuracy: 0.4762 - val_loss: 0.7244 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3340 - accuracy: 0.8571 - val_loss: 1.4876 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9667 - accuracy: 0.6190 - val_loss: 0.3859 - val_accuracy: 0.8333\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2499 - accuracy: 0.8571 - val_loss: 0.4801 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4766 - accuracy: 0.8095 - val_loss: 0.5450 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1764 - accuracy: 0.8571 - val_loss: 0.2374 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.5153e-04 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.1693e-04 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.4054e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2456 - accuracy: 0.8571\n",
      "Test Accuracy: 85.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      1.00      0.80         2\n",
      "         MDD       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.83      0.90      0.84         7\n",
      "weighted avg       0.90      0.86      0.86         7\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABYOklEQVR4nO3dd3xUVfr48c8zJb1AJgVSIKGGXowgoBSxoa6IBWVtrO0na1l7X8Vd3V2VdS3rdy271lUQbKsi4KqwVEXEgvSSQAqEFNLLtPP7407CpE9CJiHkvF+vec3Mvefee2bEeXJPeY4opdA0TdO6L1NnV0DTNE3rXDoQaJqmdXM6EGiapnVzOhBomqZ1czoQaJqmdXM6EGiapnVzOhBoJywRWSYi17R32fYmIqeJyM7OuLamAYieR6AdT0SkzOttCFANuDzv/59S6p2Or1XbichU4N9KqcR621d5tv+zFeeaDwxQSl3ZjlXUNCydXQFN86aUCqt5LSIZwPVKqS/rlxMRi1LK2ZF16+r0d6Y1RTcNaV2CiEwVkSwRuU9EDgGvi0hPEflMRPJE5IjndaLXMatE5HrP67kislZEFnjKpovIjDaWTRGR1SJSKiJfisiLIvLvY/1sXu/vE5Fsz/l3ish0ETkHeBC4TETKROQnT9l4EflERApFZI+I3OB1nvki8r6I/FtESoD7RaRCRGxeZcZ6vj9rW+uvdX06EGhdSS8gCugL3Ijx7/d1z/s+QCXw92aOHw/sBKKBp4B/iYi0oey7wEbABswHrmrzJ6pHRAYDtwAnK6XCgbOBDKXUcuBPwHtKqTCl1CjPIYuALCAeuAT4k4ic7nXKmcD7QA/gr8AqYLbX/quARUopR3t9Bq3r0YFA60rcwKNKqWqlVKVSqkAp9YFSqkIpVQo8AUxp5vj9SqlXlVIu4E2gNxDXmrIi0gc4GXhEKWVXSq0FPmmh3vEiUuT9AE5toqwLCASGiohVKZWhlNrbWEERSQImAfcppaqUUj8C/wSu9iq2QSn1sVLKrZSq9HyWKz3Hm4E5wNst1F87welAoHUleUqpqpo3IhIiIi+LyH5P08dqoIfnB64xh2peKKUqPC/DWlk2Hij02gaQ2UK9c5RSPbwfwNrGCiql9gC3Y9xpHBaRRSIS38R5a+pS6rVtP5DQTN3+gxFkUoAzgWKl1MYW6q+d4HQg0LqS+kPc7gIGA+OVUhHAZM/2ppp72sNBIEpEQry2JbXnBZRS7yqlTsVo8lLAkzW76hXN8dQl3GtbHyDb+3T1zl0FLMa4K7gKfTegoQOB1rWFY/QLFIlIFPCovy+olNoPbALmi0iAiEwAftVe5xeRwSJyuogEAlUYn8/t2Z0LJIuIyVOXTGA98GcRCRKRkcB1QEsd128Bc4EL0IFAQwcCrWt7FggG8oFvgOUddN0rgAlAAfA48B7GfIf2EAj8BeMzHQJigQc8+5Z4ngtEZLPn9RwgGePu4COMPpQGw229KaXWYQSXzZ7ApnVzekKZph0jEXkP2KGU8vsdSXsRka+Bd1szoU07cek7Ak1rJRE5WUT6i4jJM75/JvBxJ1fLZyJyMjAW405G0/TMYk1rg17AhxjzCLKAeUqpHzq3Sr4RkTeBC4Hf1RttpHVjumlI0zStm9NNQ5qmad1cl2saio6OVsnJyZ1dDU3TtC7l+++/z1dKxTS2r8sFguTkZDZt2tTZ1dA0TetSRKTJocK6aUjTNK2b04FA0zStm9OBQNM0rZvrcn0EmqZ1LIfDQVZWFlVVVS0X1jpdUFAQiYmJWK2+rzWkA4Gmac3KysoiPDyc5ORkml7HRzseKKUoKCggKyuLlJQUn4/TTUOapjWrqqoKm82mg0AXICLYbLZW373pQKBpWot0EOg62vLfSgeCFhR/+imukpLOroamaZrf6EDQDPuBA+Tccy/Fn3za2VXRtG6roKCA0aNHM3r0aHr16kVCQkLte7vd3uyxmzZt4rbbbmv1NX/88UdEhOXLO2qJi86lO4ubYT9gLPfqzMvr5JpoWvdls9n48ccfAZg/fz5hYWHcfffdtfudTicWS+M/ZWlpaaSlpbX6mgsXLuTUU09l4cKFnHPOOW2qty9cLhdmc1NLbHccfUfQDEdWFgDOgvxOrommad7mzp3LTTfdxPjx47n33nvZuHEjEyZMYMyYMUycOJGdO3cCsGrVKs4//3zACCLXXnstU6dOpV+/fjz//PONnlspxZIlS3jjjTf473//W6fj9cknn2TEiBGMGjWK+++/H4A9e/ZwxhlnMGrUKMaOHcvevXvrXBfglltu4Y033gCMNDn33XcfY8eOZcmSJbz66qucfPLJjBo1iosvvpiKigoAcnNzmTVrFqNGjWLUqFGsX7+eRx55hGeffbb2vA899BDPPffcMX+f+o6gGY4s447AlV/QyTXRtOPDY59uZVtO+/aZDY2P4NFfDWv1cVlZWaxfvx6z2UxJSQlr1qzBYrHw5Zdf8uCDD/LBBx80OGbHjh2sXLmS0tJSBg8ezLx58xqMt1+/fj0pKSn079+fqVOnsnTpUi6++GKWLVvGf/7zH7799ltCQkIoLCwE4IorruD+++9n1qxZVFVV4Xa7yczMbLbuNpuNzZuN1UYLCgq44YYbAHj44Yf517/+xa233sptt93GlClT+Oijj3C5XJSVlREfH89FF13E7bffjtvtZtGiRWzcuLHV3119OhA0w56VDYCzQAcCTTveXHrppbXNKsXFxVxzzTXs3r0bEcHhcDR6zHnnnUdgYCCBgYHExsaSm5tLYmJinTILFy7k8ssvB+Dyyy/nrbfe4uKLL+bLL7/kN7/5DSEhIQBERUVRWlpKdnY2s2bNAozJXL647LLLal//8ssvPPzwwxQVFVFWVsbZZ58NwNdff81bb70FgNlsJjIyksjISGw2Gz/88AO5ubmMGTMGm83m61fWJB0ImqGbhjStrrb85e4voaGhta9///vfM23aND766CMyMjKYOnVqo8cEBgbWvjabzTidzjr7XS4XH3zwAf/5z3944oknaidolZa2bjE3i8WC2+2ufV9/XL933efOncvHH3/MqFGjeOONN1i1alWz577++ut54403OHToENdee22r6tUU3UfQDEfm0aYhvZKbph2/iouLSUhIAKhti2+Lr776ipEjR5KZmUlGRgb79+/n4osv5qOPPuLMM8/k9ddfr23DLywsJDw8nMTERD7++GMAqqurqaiooG/fvmzbto3q6mqKior46quvmrxmaWkpvXv3xuFw8M4779Runz59Ov/4xz8AI0AVFxcDMGvWLJYvX853331Xe/dwrHQgaIKrtBRXcTFmmw1lt+MuK+vsKmma1oR7772XBx54gDFjxjT4K781Fi5cWNvMU+Piiy+uHT10wQUXkJaWxujRo1mwYAEAb7/9Ns8//zwjR45k4sSJHDp0iKSkJGbPns3w4cOZPXs2Y8aMafKaf/zjHxk/fjyTJk0iNTW1dvtzzz3HypUrGTFiBCeddBLbtm0DICAggGnTpjF79ux2G3HU5dYsTktLUx2xME3V9u2kz7qIsOnTKfvqK/p9/jmB/XzP3aFpJ4rt27czZMiQzq6G5uF2u2tHHA0cOLDRMo39NxOR75VSjY6l9dsdgYi8JiKHReSXFsqdLCJOEbnEX3VpC7unfyB49CgAXLqfQNO0TrZt2zYGDBjA9OnTmwwCbeHPzuI3gL8DbzVVQETMwJPAF36sR5s4PCOGgkcZgUCPHNI0rbMNHTqUffv2tft5/XZHoJRaDRS2UOxW4APgsL/q0VaOzExM4eEE9usHgFPPJdA07QTVaZ3FIpIAzAL+4UPZG0Vkk4hsyuugdA/27CysiYmYe/YEk0kPIdU07YTVmaOGngXuU0q5WyqolHpFKZWmlEqLiYnxf80AR2YWAYmJiNmMOSpKzy7WNO2E1ZkTytKARZ7c2dHAuSLiVEp93Il1AoxcI47sbMKmTAHAYrPpPgJN005YnXZHoJRKUUolK6WSgfeB3x4PQQCMbKOquhprojFBxQgEumlI0zrDtGnTWLFiRZ1tzz77LPPmzWvymKlTp9LUMPP8/HysVisvvfRSu9azK/Pn8NGFwAZgsIhkich1InKTiNzkr2u2l5rUEgFJSQCYo2248nQg0LTOMGfOHBYtWlRn26JFi5gzZ06bzrdkyRJOOeUUFi5c2B7Va9KxTGzraP4cNTRHKdVbKWVVSiUqpf6llHpJKdUgDCul5iql3vdXXVqrJhBYPcmoLLZonAU6zYSmdYZLLrmEpUuX1i5Ck5GRQU5ODqeddhrz5s0jLS2NYcOG8eijj/p0voULF/LXv/6V7Oxssjz/rwO89dZbjBw5klGjRnHVVVcBjaeCzsjIYPjw4bXHLViwgPnz5wPGncjtt99OWloazz33HJ9++injx49nzJgxnHHGGeTm5gJQVlbGb37zG0aMGMHIkSP54IMPeO2117j99ttrz/vqq69yxx13HMtX5zOddK4Rdk+OIasnd4kl2oaqrsZdXo45LKwzq6ZpnWvZ/XBoS/ues9cImPGXJndHRUUxbtw4li1bxsyZM1m0aBGzZ89GRHjiiSeIiorC5XIxffp0fv75Z0aOHNnkuTIzMzl48CDjxo1j9uzZvPfee9x1111s3bqVxx9/nPXr1xMdHV2bYrqxVNBHjhxp9uPY7fbaZqkjR47wzTffICL885//5KmnnuKvf/0rf/zjH4mMjGTLli215axWK0888QRPP/00VquV119/nZdffrm132ab6FxDjXBkZWOJjcXkyVRo9qR5deXr5iFN6wzezUPezUKLFy9m7NixjBkzhq1bt9bm42nKe++9x+zZswEjxXRN89DXX3/NpZdeSnR0NGAEn5rtNX0RNamgW+KdYjorK4uzzz6bESNG8PTTT7N161YAvvzyS26++ebacj179iQsLIzTTz+dzz77jB07duBwOBgxYkTLX0470HcEjXBkZdU2CwFYoo0hq86CAgKSkzupVpp2HGjmL3d/mjlzJnfccQebN2+moqKCk046ifT0dBYsWMB3331Hz549mTt3boN0z/UtXLiQQ4cO1Wb5zMnJYffu3a2qS2tSTN96663ceeedXHDBBaxataq2Cakp119/PX/6059ITU3lN7/5TavqdSz0HUEj7FlZBCR5BwLjjkDPLta0zhEWFsa0adO49tpra+8GSkpKCA0NJTIyktzcXJYtW9bsOXbt2kVZWRnZ2dlkZGSQkZHBAw88wMKFCzn99NNZsmQJBZ5h4jVNQ42lgo6Li+Pw4cMUFBRQXV3NZ5991uQ1vdNjv/nmm7XbzzzzTF588cXa9zXNTePHjyczM5N33323zZ3hbaEDQT3Kbsd56BDWBK9A4Gka0kNINa3zzJkzh59++qn2B3LUqFGMGTOG1NRUfv3rXzNp0qRmj28uxfSwYcN46KGHmDJlCqNGjeLOO+8EGk8FbbVaeeSRRxg3bhxnnnlmndTR9c2fP59LL72Uk046qbbZCYwlKY8cOcLw4cMZNWoUK1eurN03e/ZsJk2aRM+ePVv9HbWVTkNdjz0jg73nzKD3n/5Ej4uMfzTK6WTHiJFEz7uJmNtu89u1Ne14pNNQd6zzzz+fO+64g+nTp7f5HMdNGuquqmadYu+mIbFYMPfsqZuGNE3zm6KiIgYNGkRwcPAxBYG20J3F9dSfQ1BDp5nQNM2fevTowa5duzrl2vqOoB5HViZitWKJja2z3Rxt08NHNU07IelAUI89KxtrfDxSby3QmtnFmqZpJxodCOqpP4eghiVaBwJN005MOhDU48jMxJrUWCCwoSorcZeXd0KtNE3T/EcHAi+u0lJcxcUENHJHYLYZY4D1XYGmdayCggJGjx7N6NGj6dWrFwkJCbXvaxLRNWXTpk3c1soh38nJyeR3s/5APWrIy9ERQ0kN9h2dXZxPQJ8+HVovTevObDYbP/74I2BM0AoLC+Puu++u3e90OrFYGv8pS0tLIy2t0aHzmhd9R+DF3sTQUfCaXdzN/lLQtOPR3Llzuemmmxg/fjz33nsvGzduZMKECYwZM4aJEyeyc+dOAFatWsX5558PGEHk2muvZerUqfTr14/nn3/e5+tlZGRw+umnM3LkSKZPn86BAwcAY22DmtnBkydPBmDr1q2MGzeO0aNHM3LkyFbnMuoM+o7Ai6NmMplnZTJvNU1DLt00pHVjT258kh2FO9r1nKlRqdw37r5WH5eVlcX69esxm82UlJSwZs0aLBYLX375JQ8++CAffPBBg2N27NjBypUrKS0tZfDgwcybNw+r1dritW699VauueYarrnmGl577TVuu+02Pv74Y/7whz+wYsUKEhISKCoqAuCll17id7/7HVdccQV2ux2Xy9Xqz9bRdCDw4sjMxBQejqmRVLOWKCPvh55drGnHh0svvRSzZ5h3cXEx11xzDbt370ZEcDgcjR5z3nnnERgYSGBgILGxseTm5pLYSAtAfRs2bODDDz8E4KqrruLee+8FYNKkScydO5fZs2dz0UUXATBhwgSeeOIJsrKyuOiiixg4cGB7fFy/8lsgEJHXgPOBw0qp4Y3svwK4DxCgFJinlPrJX/XxhT3bGDoqIg32idVqpJnQiee0bqwtf7n7i3e659///vdMmzaNjz76iIyMDKZOndroMYGeNUbAWF/gWJeTfOmll/j2229ZunQpJ510Et9//z2//vWvGT9+PEuXLuXcc8/l5Zdf5vTTTz+m6/ibP/sI3gDOaWZ/OjBFKTUC+CPwih/r4hNHZlajI4ZqWKJtumlI045D3ume33jjjXY//8SJE2sXxnnnnXc47bTTANi7dy/jx4/nD3/4AzExMWRmZrJv3z769evHbbfdxsyZM/n555/bvT7tzZ9rFq8GCpvZv14pVbPm2zdAy/dnfqSUwpGd3WhHcQ2zLVo3DWnacejee+/lgQceYMyYMe2yaPzIkSNJTEwkMTGRO++8kxdeeIHXX3+dkSNH8vbbb/Pcc88BcM899zBixAiGDx/OxIkTGTVqFIsXL2b48OGMHj2aX375hauvvvqY6+Nvfk1DLSLJwGeNNQ3VK3c3kKqUur6J/TcCNwL06dPnpP3797d3VXEcPsyeyVOI+/3DRF1xRaNlsu+6m8qff2bAf79o9+tr2vFKp6HuerpcGmoRmQZch9Ff0Cil1CtKqTSlVFpMTIxf6lEzhyAgqeEcghqWaJ2BVNO0E0+nBgIRGQn8E5iplOrUX9im0k97M9uiURUVuCsqOqpamqZpftdpgUBE+gAfAlcppTonCbcXe2YmANaEhnMIahxdslLfFWiaduLw5/DRhcBUIFpEsoBHASuAUuol4BHABvyfZ7ims6n2q47gyMrGEhuLyWt4WX110kw004SkaZrWlfgtECil5rSw/3qg0c7hztBU+mlv5mg9u1jTtBNPp3cWHy/sWVl11ilujMUTCPQQUk3TTiQ6EADKbsd56BDWhBYCQVQUgJ5drGkdaNq0aaxYsaLOtmeffZZ58+Y1eczUqVPZtGmTz9u7Ox0IAMfBg6BUi01DYrVijozUGUg1rQPNmTOndlZvjUWLFjFnTrOtz1or6EAA2DNr5hC0PLnZHB2NSzcNaVqHueSSS1i6dGntIjQZGRnk5ORw2mmnMW/ePNLS0hg2bBiPPvpom85fWFjIhRdeyMiRIznllFNqU0L873//q10AZ8yYMZSWlnLw4EEmT57M6NGjGT58OGvWrGm3z9mZdPZRfJtDUMNi05PKtO7r0J/+RPX29k1DHTgklV4PPtjk/qioKMaNG8eyZcuYOXMmixYtYvbs2YgITzzxBFFRUbhcLqZPn87PP//MyJEjW3X9Rx99lDFjxvDxxx/z9ddfc/XVV/Pjjz+yYMECXnzxRSZNmkRZWRlBQUG88sornH322Tz00EO4XC4qTpA5RfqOAHBkZSJWK5bY2BbLGrOLddOQpnUk7+Yh72ahxYsXM3bsWMaMGcPWrVvZtm1bq8+9du1arrrqKgBOP/10CgoKKCkpYdKkSdx55508//zzFBUVYbFYOPnkk3n99deZP38+W7ZsITw8vP0+ZCfSdwSAPSsba3w84slt3hzdNKR1Z8395e5PM2fO5I477mDz5s1UVFRw0kknkZ6ezoIFC/juu+/o2bMnc+fOpaqqqt2uef/993Peeefx+eefM2nSJFasWMHkyZNZvXo1S5cuZe7cudx5551dIqlcS/QdAb7NIahhsUXjLi/H3Y7/4DRNa15YWBjTpk3j2muvrb0bKCkpITQ0lMjISHJzc1m2bFmbzn3aaafxzjvvAMbSltHR0URERLB3715GjBjBfffdx8knn8yOHTvYv38/cXFx3HDDDVx//fVs3ry53T5jZ9J3BBgrkwUNH+ZT2aOziwsaXdJS0zT/mDNnDrNmzaptIho1ahRjxowhNTWVpKQkJk2a5NN5zjvvvNrlKSdMmMDLL7/Mtddey8iRIwkJCeHNN98EjCGqK1euxGQyMWzYMGbMmMGiRYt4+umnsVqthIWF8dZbb/nnw3Ywv6ah9oe0tDTVnuOAXaWl7Dp5HLF334Xt+pYnOpeuWkXWTfNIXrSQ4NGj260emna80mmou54ul4a6sx0dMeRb7iCLZxF7PXJI07QTRbcPBPZWDB2Fuk1DmqZpJ4JuHwgcWdkAPrf3m2tTUeshpFr30dWakLuztvy30oEgMxNTeDimyEifypsCAjBFROghpFq3ERQUREFBgQ4GXYBSioKCAoKCglp1XLcfNWTPNoaOetZE8IklOlr3EWjdRmJiIllZWeTl5XV2VTQfBAUFkehjU3eNbh8IHJlZBPbv16pjjDQTumlI6x6sVispKSmdXQ3Nj7p105BSCkd2ts8jhmqYo226aUjTtBNGtw4Ezrw8VHU11lZODLPYonUqak3TThh+CwQi8pqIHBaRX5rYLyLyvIjsEZGfRWSsv+rSlJo5BK1df9gSbcNdVoa7utof1dI0TetQ/rwjeAM4p5n9M4CBnseNwD/8WJdGtSb9tLeaIaQufVegadoJwJ+L168WkeRmiswE3lLGmLRvRKSHiPRWSh30V53qq51MltD6piEwZhe39tjOVlbt5Lkvd3HVKcn0sYX4dpBSsPppyPmhVdc6WFzFoRKdnE/T2otz0HmcfOEt7X7ezhw1lABker3P8mxrEAhE5EaMuwb69OnTbhVwZGZhiY3FFBjYquMsMV13Eft/rtnHq2vS2ZheyPvzJmI1+3BTuO0/sPIJsA0Eq2/jkysdbo7klRFqNmE2+T40V9O0puVVFvvlvC0GAhHpD2QppapFZCowEuMv+SK/1KgRSqlXgFfASDrXXudtTfppb5YuOru4sNzOP9ekkxIdyk9Zxbzw9R7uPHNQ8wfZy2HFQxA3HG78H5hb/tuh0u7i/BfWUB7kYvntp9EjJKCdPoGmdW/9/XReX/oIPgBcIjIA48c4CXi3Ha6d7TlXjUTPtg5jz8ryaZ3i+mr7CLrYpLKX/reXcruTV646iYvGJvDiyj1sPnCk+YPW/BVKsuDcBT4FAYAnl+9gb145T186UgcBTesCfAkEbqWUE5gFvKCUugfo3Q7X/gS42jN66BSguCP7B5TdjvPQIawJrQ8EpsBATOHhOPMavyM4XHGYUnvpsVaxXeWWVPHm+gxmjUlgYFw48y8YRq+IIO5870cq7M7GDyrYC+tfgJGXQ98JPl1n9a483lifwdyJyZw2MKYdP4Gmaf7iSyBwiMgc4BrgM882a0sHichCYAMwWESyROQ6EblJRG7yFPkc2AfsAV4Fftvq2h8Dx8GDoFSbmoag+UXsr1txHQs2LTiW6rW7F77ejVsp7jjDaAqKCLLy19mj2F9YweNLtzc8QClYdi+YA+HMx3y6RlGFnXve/4kBsWHcPyO1PauvaZof+XKv/xvgJuAJpVS6iKQAb7d0kFJqTgv7FXCzT7X0A3tmzRyCtgUCY3ZxwzuCCkcFGSUZhAccP4taHyioYNHGTOaM60NS1NGRQqf0s3Hjaf14efU+zhgSy+mpcUcP2rEU9nwJZ/8Jwnu1eA2lFA999AsFZXb+dc3JBFlbXv9Z07TjQ4t3BEqpbUqp25RSC0WkJxCulHqyA+rmV22dQ1DDYms88VxGSQYAmaWZDfZ1lme/3IXZJNxy+oAG++48axCpvcK59/0tFJR5JsjZK2D5AxAzBMbd6NM1/vNjDku3HOSOMwcxPMG3TK6aph0fWgwEIrJKRCJEJArYDLwqIs/4v2r+5cjKRKxWLLGxbTq+qaah9OJ0AIqqiyixlxxTHdvDrtxSPvoxm7kTk4mLaDj0M9Bi5tnLR1NS6eCBD7cYqYbX/g2KD8B5C8DcYisg2UWV/P4/v5DWtyc3TfHXuAZN0/zFlz6CSKVUCXARxrDR8cAZ/q2W/9mzsrHGxyPmtjVhWGKicZeU4Lbb62yvCQRwfNwVPPPFLkIDLM3+QKf2iuCeswfzxbZcPl+9HtY9B8MvgeRTWzy/2624a/GPuN2KZ2aP1nMGNK0L8iUQWESkNzCbo53FXV5b5xDUaGoI6b7ifVhMRtdLZknnBoKfMotYvvUQN5zWj56hzQ/jvO7UFCb0sxH69cO4TRY463GfrvGvtel8s6+QR381zPeZypqmHVd8CQR/AFYAe5VS34lIP2C3f6vlf47MTKxt7CgGY3EaaDi7OL04nZNiTwI6/45gwRc7iQoN4LrTWs4lbzIJf0/LZaps5t+Bl+MKa7mDeMehEp5esZOzhsZxaVrbv0tN0zqXL53FS5RSI5VS8zzv9ymlLvZ/1fzHVVqKq7iYgGO4I6idXZx/dNUml9vF/pL9DLUNJSY4hgOlB465rm31zb4C1uzOZ96U/oQF+jA4zFGFbfXvKQnrxx/yp/Dy6r3NFq92urh90Y9EBFv480UjWrXCm6ZpxxdfOosTReQjT0rpwyLygYh06T//jnXEEIDZk3jOu2kopywHh9tBSmQKSeFJHCjpnECglGLBip3ERQRy1YS+vh207jko2k/4RX/j7JFJ/O2/u/glu+m8Js98sYsdh0p56pKR2MJal6tJ07Tjiy9NQ69jzAKO9zw+9WzrsmqzjrZyZTJvluiaO4KjgWBf8T6A2kCQVZp1DLVsu1U789i0/wi3TR/o23j+Ixmw9hkYNgvpN5UnLhxOVGgAd7z3I1UOV4Pi3+wr4JU1+/j1+D515x5omtYl+RIIYpRSryulnJ7HG0CXzh3gyDJSGgW0cmUyb6agIEyhoXWGkNaMGEqJTKFPRB8OVx6m0ll5bJVtJbdb8fSKnfSJCmF2mo+BbvmDIKbaDuIeIQEsuHQUuw+X8eTyHXWKllQ5uGvxT/SNCuGhc4e0d/U1TesEvgSCAhG5UkTMnseVQNfKtlaPIzMTU3g4pshjm/hkiY7G5ZWBNL0knaigKCIDI0kKN36EO/qu4PNfDrLtYAl3njnItxTTu/8LO5fC5Hsg8mhT2WkDY5g7MZnX12WwdvfRzzj/k60cKqnimctGE+pL34Omacc9XwLBtRhDRw9hrBVwCTDXj3XyO3u2MXT0WDs4zdHRdZqG0ovTSYk0Ruj0CTfWTejIDmOny80zX+xiUFwYvxoV78MB1UY+IdsAmNBwsYv7Z6TSPyaUu5f8RHGFg8+3HOTDzdncPG0AY/v09MMn0DStM/gyami/UuoCpVSMUipWKXUh8Dv/V81/HFnZx9QsVMN7drFSin3F++gX2Q+AxHDjr+uOvCP48Ids9uWXc9dZg32b2LX+eSjcBzOeAkvDeQZBVjPPXT6G/LJq7lj8Iw9+tIVRiZHc2kiqCk3Tuq62rlk8u11r0QF2H9nN377/G+X2cs9kspbbzx0uN4/+5xf25pU1ut8SbcPpSTx3pPoIxdXFtXcEkYGRRAZG+jxy6Mttucz/ZCsZ+eU+fqK6qp0unvtyN6MSIzlrqA8duEUHYPVfYcivYMD0JosNT4jkjjMH8fWOw1Q5XDxz2Wjfmpw0Tesy2trI2+UGjWeVZvHaL68xNXgUQdXVWH24I/h+/xHe3LCfwgoHL8wZ02C/2WbDXVyMstvrdBTXSApL8mlSmcutePSTrWQXVfLWhgzOHxnPb6f1J7VXhM+fb+G3B8guquTJi0f61uS14kHj+ew/t1j0pin9yS6qZFL/aPrHhPlcJ03TuoYmA4EnyVyju+iCgWCIzRjhcmDHdwwCApJaviNYv8f4a3/ZloMcPm8IsfWSttUuYl9YyL4SY+hoTdMQQFJEEj/n/dzidb7ankt2USV/vHA4WYUV/Pub/XzyUw5nDInj5mn9GdNCe3yF3cnfV+5hQj8bkwbYWrwee76C7Z/C6Q9Dj5a/B7NJ+NOsES2fV9O0Lqm5O4Lvm9lnb2bfcSkuJI4egT0o2LcN8G0y2bq9BST0CCa7qJKFGzP53RkD6+z3nkuQXplOkDmIXqG9YPtnENGbpPAkVmSswOFyYG0mi+fb3+ynd2QQc05OwmI2MW9qf95Yn8Hr6zKY9X+5TBpg4+apA5jQ39boX/tvrM8gv8zOy1cNbvluwGmHZfdBVD+YeFuL34GmaSe+5hp7ByulUpp49GvmuOOSiJAalUrlgQwArAnNNw2VVTv5KbOImaPjmTwohnc37sfhctcpczTxXD7pxekkRyZjclbDhzfAe1fRJzgWt3KTU57T5HX25ZWxZnc+vx7XB4un7b1HSAC3nzGIdfefzoPnprIrt4xf//NbLvrHer7clmukivYornTw0qq9TE+N5aS+PozkSf8fFOyGMx4Di54RrGla84FgvYh87FleMrktJxeRc0Rkp4jsEZH7G9nfR0RWisgPIvKziJzbluv4akjUEMyHCjDHxmIKbP5HcGN6AU63YtKAaK4+pS+5JdX8d1tunTKWGGNenTO/4OjQ0fQ14KiAkmz67F0D0GyH8dvf7MdqFi4f16fBvrBACzdO7s+ae6fx+IXDySut5vq3NjHjuTV88lMOLrfi1dX7KKlyctdZg337EnYuA2soDDzLt/Kapp3wmgwESqk04HbP22dF5DsR+ZuInCUiLf4pKSJm4EVgBjAUmCMiQ+sVexhYrJQaA1wO/F8bPoPPUqNSiS5y4erVcjv6uj0FBFhMnNS3J9NSY0noEcxbGzLqlKlJPFeVd4icshwjEOxabvzQDr+YpB8WA01nIa2wO3n/+yxmDO9NTHjTX2mQ1cyVp/Rl5d1TeWb2KJxuxW0Lf2D6X1fx2rp0fjUqnqHxPnQsKwW7VkD/aWBtuEiNpmndU7PjAJVSGUqplzxzByZi5Bk6A1gjIktbOPc4YI8nW6kdWATMrH8JoOYXLBJoug2lHaTaUokrgmJby00i6/cWkNa3J0FWM2aTcOUpfflmXyG7cktry5iCgzGFhHDkYAYKRUpEytEf2nP+gs0cSDBCZhOTyj7+IYfSKidX+5gYzmo2cdHYRL64fTIvXTmWsCCLZ0H6gS0fDJD7C5RkwaCzfSuvaVq34Ev20V+JiEkp5VBKfa2UulcpNQ5oaTHbBMD7T+EszzZv84ErRSQL+By41feqt16fwHiiSuBgpGq2XEFZNdsPljCx/9E7h8tOTiLAYuLtDfvrlDVHR1N+yJg0luJ0eX5oz4GwWGTagyRVV5OZs6nBNZRSvLUhgyG9I3xr2/diMgnnDO/Np7ecyvcPn0k/X4d07lpuPA/UgUDTtKN8mRl0GbBbRJ4SkdSajUqp7Ha4/hzgDaVUInAu8LaINKiTiNwoIptEZFNeXl6Dk/jKnZuLCdgb3Pxawhv2GbOFJw6Irt0WFRrA+SN78+HmLEqrHLXbLTYb9vw8BCE5e4uxsab9/eQb6GMO4UDhDmNBeC+b9h9hx6FSrp7Qt82pLkSkdfl+di6H+LEQrjOGapp2lC8pJq4ExgB7gTdEZIPnhzm8hUOzAe9B6omebd6uAxZ7rrMBCAKi65VBKfWKUipNKZUWE9P2xKf2TOMv958DDuNW7ibLrdtTQHighZEJdZPSXT0hmXK7i49+OPoxLNE2KCwiISyBwN3/hYSTjv7Qmi0kJU8jywSu1U/XOddbG/YTHmRh5mgfcgK1h7LDkP09DJ7RMdfTNK3L8ClXgGfx+vcx2vl7A7OAzSLSXFPOd8BAEUkRkQCMzuBP6pU5AEwHEJEhGIGg7X/yt6BmQZoDYVXN5gBavzef8f2iaodz1hid1IORiZG8tWF/7RBOs81GQHElKWEJxg/toHPqHJOUNAGHCIc3/h8UGKt+HS6tYvkvB7n0pCRCAjoog+fuLwCl+wc0TWvAlz6CC0TkI2AVYAXGKaVmAKOAu5o6TinlBG7BWO94O8booK0i8gcRucBT7C7gBhH5CVgIzFXeg+TbmSMrE2WxUBgGOwp3NFom60gF+wsqmNi/wY0JAFed0pc9h8tqm4/M0dGEVrjoX+3E+KGtFwg86agzA4KNiVxKsWhjJg6X8n31sPawazmEx0OvkR13TU3TugRf7gguBv6mlBqhlHpaKXUYQClVgdG00ySl1OdKqUFKqf5KqSc82x5RSn3ieb1NKTVJKTVKKTVaKfXFMX6eZtmzsglIiMdktjQZCNbvMX7gJw1oPBD8alQ8PUKstZ3GZWHGCmADcrIhIgF61U3FUJuOeth5sOe/uLYv5d1vD3DawGhSokPb5XO1yFkNe1cadwN6bWFN0+rxJRDMBzbWvBGR4JoJZkqpr/xTLf9wZGURkJhEvx792F64vdEy6/bmEx0WyKC4xkfiBFnNXJaWxBfbcjlYXElekNFx3Cdjd6M/tHEhcVhNVg5Ep0DMEKo/u5cjJSVcPSG5XT9bszLWgr1M9w9omtYoXwLBEsC7Z9Xl2dblODIzsSYlktoztdE7AqUU6/cWMLGJnD41rjylL26ljIyfViNFde+iygbNQgBmk5mEsASyynPg3KcJqcjmvtDPOT01tv0+WEt2rQBLMKRM7rhraprWZfgSCCyeCWEAeF43XMXkOOcqLcVVXExAYiKpUankV+aTX5lfp8zuw2XklVa3mMEzKSqEaYNjeXdjJntMhQAEVQc2+UPbJ6IPB0oOsCtkNJ+4JnC1+2PMRent88FaohTsWgb9poI1uGOuqWlal+JLIMjz6txFRGYC+c2UPy7VjBiyJibWpqTeXlC3eagm7XRTHcXerprQl/yyar6tMGYNO0MGNPlDmxRurEvw1voMnnZfhdliheUPtPmztEreDmMRGj1aSNO0JvgSCG4CHhSRAyKSCdwH/D//Vqv92WsDQRKDo4wEbfWbh9btLaBPVAhJUSEtnm/KwBj62kJIt+/HaVG4rE1nM00KT6LCWcFHP+/g5JHDkKn3GaN4di5v+wfy1c5lxrMOBJqmNcGXCWV7lVKnYCSOG6KUmqiU2uP/qrWvwAEDiL3nbgKS+xIREEFCWEKdDmOny803+wp8W9gFI83DxWk9cZgqcAYrnCqyybI1Q0gryTOGjI6fB9GDYPl94Kg6tg/Wkl0roPcoiOigiWuapnU5Pk0oE5HzgN8Cd4rIIyLyiH+r1f4CU1KwXXcd5jBjNNCQqCHsLNxZu/+XnBJKq5xM8KFZqMbo/kbXiTvEgrOk6bWGawJB37gKRif1MBaKP/dpOJJhLCDvL+UFkLURBunRQpqmNc2XCWUvYeQbuhVjicpLgQ6cCeUfqVGpHCg9QJndGPWzrrZ/wLc7AoD8EqNpqcgajj2v6W6TzMNBKCUM6eM4Ohqp31QYeiGs+Ssc2d/kscdkz39BuXWzkKZpzfLljmCiUupq4IhS6jFgAjDIv9Xyv5oO451HjLuC9XvzSe0VTnSY76t2pR9YQ4Bbsd+SQGVu05kxFn6bg7h6EhJypO6Os58AMR1dSL697VwGYXHQe7R/zq9p2gnBl0BQ04hdISLxgAMj31CXNrjn0Q7jKoeLTRlHfBot5C29YBvJbkVlTD/MpSW47I4GZQ4WV/LFtlzighPIKa+X3ygyESbfAzs+g91ftvmzNMpph71fG3cDJp9aADVN66Z8+YX4VER6AE8Dm4EM4F0/1qlDxIbEEhUUxfaC7Wzef4Rqp9vnjmIAnHb22Y+QEhzH0OEpmFBs+KFhH/rCbw/gVoqxvQc0vlLZhJvBNgCW3WOkgmgvB9ZDdUmjk9w0TdO8NRsIPGsDfKWUKlJKfYDRN5CqlOpyncX11Sxmv6NwB+v25mM2CeNSonw+vjrjf2SbTaTEjmTkyH4AfL56W50ydqebdzdmMnVQDENj+lFUXUSJvd5aCJZAmPEkFO6D9S8c8+eqtWsFmAONvghN07RmtLRUpRtj3eGa99VKqWK/16qDpEalsrdoL2v3HGJUYiThQVafjz2w42PcIvTrO5XgWGONhF3b95N15OgCNMu3HiK/rJqrJyQfzULa2F3BgDMg9XxYvQCKGl/fuFWUMvoHUiZDQAclttM0rcvypWnoKxG5WNq6jNZxbEjUEJzKyda8XU1mG22UUuw7sBaAFFsqlmjj2B7Vpbzz7dH1id/ekEGfqBCmDIohKcITCEqa+KE/58/Gc3t0HOfvhiPpMFg3C2ma1jJfAsH/w0gyVy0iJSJSKiLNr/XYRaRGeVbeDMxpXUdx/m7S7YUI0DeiL2abcezJkfDed5lUOVxsyynhu4wjXHlKH0wmITEsEWjijgCgRx847S7Y/onRyXss9NrEmqa1gi8zi8OVUialVIBSKsLzPqIjKudvfSL6YCGIgJCDjO3bw/cDdy0n3WolPiSOYEswptAQJCiItAhFYbmdz7cc5O1vMgi0mJidZtwJhFhDiAmO4UDpgabPO/FW6JkCn99rjPppq13LIW4E9Ehquaymad2eLxPKJjf26IjK+ZtJTJgc8UREHibQYvb9wF3LSQ8JJ7nnAMDoeLbYbMQ5y+kXE8orq/fx8Q85zBwdT4+Qo4laa5LPNckaBDOegoLd8M2LTZdrTkUhHPhGTyLTNM1nvjQN3eP1+D3wKcZiNV1eXmk1ZaVx2E1ZzS5mX0dFIe4D35BhFlIiUmo3m6NtuAsLuOqUvuw4VEqlw9Vg8Zmk8KSm+whqDDoLBp8L/3sairNb+YmAPV+BculFaDRN85kvTUO/8nqcCQwHjrR0HICInCMiO0Vkj4jc30SZ2SKyTUS2ikiHzk9Yvzcfd1U8DlXFgZJmmmy87fmKXBNUKhcpkUcDgcUWjTO/gItPSiQkwMyYPj0YnlA3EV1SeBKHKw9T6axs/hrn/Nn4Mf/i4dZ+JKNZKDQG4se2/lhN07qltkw5zQKGtFRIRMwYQ09nYGQunSMiQ+uVGQg8AExSSg0Dbm9Dfdps/Z4CgpTRjt7UGsYN7FpOergx8axfZL/azRabDWdBARFBVt66dhzPzB7d4NA+Ecb6xVmlWQ321dEzGU69A7Z+COmrfasXgMth5BcaqGcTa5rmO1/6CF4Qkec9j78DazBmGLdkHLBHKbXPs6rZImBmvTI3AC8qpY4AKKUOt676x2bd3nzGJwzFIpYm1zCuw/NDu6+3Ec+87wjM0TZcR46gXC7SkqMaXZi+diH75jqMa0z6HfToC5/fY1zXF5nfQlWx7h/QNK1VfPmzcRPwveexAbhPKXWlD8clAN4N4lmebd4GAYNEZJ2IfCMijQ58F5EbRWSTiGzKy2s6uVtrHCioIOtIJacN7E3/Hv3rpKRukueHNj08moiACKKCjs5EtkRHg9uN60jTrWaJ4cYQ0hbvCMBY7WzGk8YKY9++1HJ5MCaRmQOg/zTfymuapgEWH8q8D1QppVxgNPmISIhSqqKF43y9/kBgKpAIrBaREUqpIu9CSqlXgFcA0tLSVDtcl3V7jbTRkwbY2O1OZU32GpRSzS5aX/NDmy5O+kX2q1PW4plL4CwoqJ1gVl9kYCSRgZG+90cMnmE086z6Cwy/BCJayPW3awUknwqB4b6dX9M0DR9nFgPei/EGA76kyswGvAeyJ3q2ecsCPlFKOZRS6cAujMDgd+v25BMbHkj/mDCG2IZQWFVIXmULdxueH9r00gN1moUALNFGv4Ezv/nlnJPCWhhCWt+MvxhNQ//9ffPlCvYaw051kjlN01rJl0AQpJQqq3njed3yor7wHTBQRFJEJAC4HPikXpmPMe4GEJFojKaifT6c+5gopdiwt4BJA6Jrk89BCx3Gnh/akv7TyK/MbxAIzDYjELhaCgQRSb71EdSI6mf0F2xZAhlrmy5XM5tY9w9omtZKvgSCchGpHYsoIicBLYx/BKWUE7gFWAFsBxYrpbaKyB9E5AJPsRVAgYhsA1YC9yilClr7IVprZ24pBeX22tXIatYm2F7QTIex54c2Pc5Yk6fhHYGnaSi/+eonhSdxsPwgDl87gMEYQRTZp/mO453LIGaIMeJI0zStFXzpI7gdWCIiORhLVfbCWLqyRUqpz4HP6217xOu1Au70PDrMuj3Gj3VNormwgDCSwpOavyPYtRxihpCujHV6vIeOApjCwpCAAJwFzQeCPuF9cCs3OeU59I3wccXPgBBjbsF7V8DGV2HCb+vuryyCAxuMFBWapmmt5MuEsu+AVGAecBMwRCn1vb8r5k/r9+STEh1KfI+jXR+pUalNDyGtKob962HwOaQXp2M1WYkPi69TRESMIaQFLTQNNZeOujmp5xnpqlf9GUpzAVBOJ47cXNj7Fbidun9A07Q28WUewc1AqFLqF6XUL0CYiPy2peOOV06Xm2/TCxssUj8kagjZZdkNF44BI22D54d2X/E++kb0xWJqeDNVM7u4OTWTynweOVRDBM55EhyV8N9HqNq5k4zLLmfP6dOp/Op9CI6CxJNbd05N0zR86yO4wXs4p2fy1w1+q5Gf/ZRVTFm1s8H6AzUdxo3OJ9i1vPaHNqM4o0H/QA1LdHSLTUO2IBvBluDW3xEARA/AffJvyXtnKekXXYzj0CHMkZEcWrIZ1f9MMLUicZ6maZqHL4HA7L0ojSd1REAz5Y9r6/cYTTen9Kt3R2AzsmY06Cdwu2D3FzDwLBzKTWZpZjOBwIazhaYhEWk5C2kTKn/6ifS/f0/+1nAiB5rp98nHxF47i6p8E8U5Ma0+n6ZpGvgWCJYD74nIdBGZDiwElvm3Wv6zbm8+Q3tHEBVaN5ZFB0cTHRzdMBBkboTKIzDobA6UHsBVL9mcN7PNhqugEOVyNVuHPuF9WjWE1F1ZSe6f/0LG5XNwl1eQ9OA1xI/OwLLnQyKTSgiOdnB44UpcJSfEekGapnUwXwLBfcDXGB3FNwFbqDvBrMuotLvYvL+ISQNsje4fHDW4YYfxruVgssCA6aQXpwMNh47WsNg8aSaKipqtR1J4ElmlWbjczQcMgPJvvmXfBTMpfPNNelx+Gf0++5Swq+4zFqX/+nFk+8fE/aofrqIi8v7+9xbPp2maVl+Lw0eVUm4R+RboD8wGooEP/F2xdldewK4fNzLSvY0ZkQr2FzcoMsQcwTdHNlC9bzWBZs9C9juWQt+JEBR5NBBENN00BMZcAout8WADxqQyh9vB4YrD9A5rPG2Eq7SUw08voGjxYqx9+9DnrTcJHTfuaIEZT8M/JkJ1McFn30SP8lyOvPMuPS65hKBBg3z5RjRN04BmAoGIDALmeB75wHsASqmumdEsYzWj/juX9wNpMkFGakgwrrgY9iy6mGF2r6Uixxl94+nF6fQK7UWItfGJ1bWziwvyMSZJN857CGljgaB05UoOzX8MZ14eUddeS8ytt2AKrncTFjMIJtwM65+HwecQk9qTkhUryH3iT/R54/XmcyZpmqZ5ae6OYAdGyunzlVJ7AETkjg6plT/0ncQjEY9jMZt45PyhjRYZUpkH3/+R7VNuZ1ivicZGsxWSxgOwr3hfk3cD4DW72IdJZWCkox7X++hf+c4jR8h94k+UfPYZgQMHkvj3FwgeMaLpE01/BEZfAVH9sAAxt91K7h8fp3TFCiLO0XMKNE3zTXOB4CKM/EArRWQ5xnoCXfbPzGJzT/6d149bTx8I/Rv/az1RuQn9+Rl2mFWDVM5KKdKL05k1cFaT1/A1zURcSBwWk6XOyKHSVas4+OBDuEpLib7lFqJvvAEJaGFwlslMRY/E2sRPPS+7jKLFS8h98inCJk/GFOJLSihN07q7JjuLlVIfK6Uux5hVvBIj1USsiPxDRM7qoPq1m2/2FeBWNJg/4M0kJgb3HNxoqonDFYepcFY0e0dgCg9HrNYWZxebTWYSwxJrA0HxJ5+QdfMtWHrFkfL++8TccnPLQQD4aPdHTF08lbwKI2uqWCz0evghnAcPkv/qqy0er2maBr6lmChXSr2rlPoVRirpHzBGEnUpQ3pFcM/Zgxmd1KP5crYh7Dqyq8GInn3FRlLUpkYMQU2aiZZnF4PRT3Cg5ABHFi4k5977CElLo+9bbxM02LeOXrdy869f/kWls5LVWUeXsww5+WQizjuPwn+9hj2zDZPWNE3rdlq1sK1S6ohS6hWl1HR/Vchf+thCuHnaAAIszX/k1KhUKp2V7C/dX2d7zYihfj36NXZYLYvN1uKaBGCkmhi+Yg+HHvsDYVOnkvTKy5jDGi5v2ZS12WvZX7Ifk5j4X9b/6uyLvfcesFjI/fNffD6fpmndl17hvJ7atQkK6jYPpRenE24NxxbU9LBQOLqIfXOUUoz7dC+XfVVN4Fmnk/jC85gCA1tVz7e2vUVsSCyzBszim4PfUO2qrt1njYsj+qabKPv6a8rWrGnVeTVN6350IKinf2R/LCZLg36C9JJ0UiJTWhyWaY62Nbs4jXK7yf3Tn+m9ZC1fjRJKHrgOsVpbVcddR3bx7cFvmZM6h+l9plPprGTToU11ykTNvYaAvn3JfeJPKO+hsJqmafXoQFCP1WxlYI+BDWYYpxelkxyZ3OLxFls0zsJClNvdYJ9yuTj4+99z5O23MV9+IS/PMHGgwoeF7Ov597Z/E2QO4tJBlzKu9ziCLcENmodMAQHEPfgA9owMCt96q9XX0DSt+9CBoBGpUansLNyJsW4OlNnLOFx5uMFiNI2xRNvA5cJVXHfmsrLbyb77boo/+JDo3/6W5Icfw2Qytzr5XEFlAUv3LeWC/hcQGRhJoDmQ8b3HszprdW19a4RNmULY1Knk/98/cOQebtV1NE3rPnQgaERqVCpHqo+QW2EsAJNRkgE0P2KoRs1cAu/mIXdVFVm33kbpsuXE3nMPMbfdSoAlgN6hvVu9LsGSXUuwu+1cMfSK2m2TEyeTXZbN3qK9DcrHPXA/yuHg8IIFrbqOpmndh18DgYicIyI7RWSPiNzfTLmLRUSJSJo/6+Or+impW0o2581sqzu72FVWTuaN/4+y1avp9dhj2K67trZsYngiWaW+Nw3ZXXYW7VjEqQmn1rk7mZwwGaBB8xBAQN++RF17LSWffkrF9116YTlN0/zEb4HAs27Bi8AMYCgwR0Qa5HYQkXDgd8C3/qpLaw3uORhBavsJ9hXvw2KykBie2OKxtYnn8vJxFRVx4Nprqfj+e+Kfeoqel82uU7a16aiXZyynoKqAq4ZcVWd7XGgcQ6KG1JlP4C36/92IpVcvDj3+RIspsjVN6378eUcwDtijlNqnlLJjpKiY2Ui5PwJPAlV+rEurhFhD6BvRt3YIaXpxOn3C+2A1tTy6pybraPWuney/Zi7V27eT+PxzRP7q/AZlk8KTKKouanx5zHqUUry97W36R/ZnQvyEBvsnJ07mx7wfKa5umFXVFBJC3L33UL19O0WLF7d4LU3Tuhd/BoIEwLsnNMuzrZaIjAWSlFJLmzuRiNwoIptEZFNeXl7717QRg6MG12ka8qVZCMAUGQlWKwWv/hP7gQMkvfwS4dMbn39Xk3zOlw7jTbmb2FG4gyuHXtnoENYpiVNwKzdrs9c2enz4jBmEjBtH3rPP4TxyxKfPomla99BpncUiYgKeAe5qqaxnNnOaUiotJqZjlmRMjUolpzyHgsoCDpQc8DkQiAjWmBhM4eH0+de/CJ04scmySRGedNQlLQeCt7e9TY/AHpzfr+GdBcCw6GFEBUU12k9QU6+4hx7CVVZG3nPP+fBJNE3rLvwZCLKBJK/3iZ5tNcKB4cAqEckATgE+OW46jKOMDuMv93+JUzl9GjpaI37B0yS/9x4hY8c0Wy4xzOhzaOmOILMkk1WZq7h00KUEWYIaLWMSE6clnMba7LU43c5GywQNHkTPOXMoem8xlVt+afmDaJrWLfgzEHwHDBSRFBEJwEhp/UnNTqVUsVIqWimVrJRKBr4BLlBKbWr8dB2rJtXEsgxjeWZf7wgAQsaOJbBfy+VDrCHEBMe02GH87o53MZvMXJ56ebPlpiRNodReyo+Hf2yyTMxtt2KJjSXnnntwV1S0WEdN0058fgsESikncAuwAtgOLFZKbRWRP4jIBf66bnuxBduIDY7l+1xjyGVyRLJfrpMUntTsHUGpvZQPd3/IOcnnEBsS2+y5JvSegMVkaXL0EIA5IoL4J5/Evn+/TkqnaRrg5z4CpdTnSqlBSqn+SqknPNseUUp90kjZqcfL3UCNVJtxVxAbEktYQJhfrpEUntRsH8FHuz+iwlnBlUOvbPFcYQFhpMWlNRsIAEJPGY/t+uspWrKEkhVftLrOmqadWPTM4mbUNA+1plmotZLCkzhceZhKZ2WDfS63i3d3vMvY2LEMsw3z6XxTEqewt3hvi/0OMbfdStCIERx85BEcBw+2qe6app0YdCBoRk2HcXOrkh2rPhHGENLGZhivzFxJdlk2Vw29qsG+pkxONGYZt3RXIFYrCQueRjkc5Nx3v55opmndmA4EzRhmG4YgDIrybdWwtkgK9wwhbeQv+Le3vU1CWALTkqY12NeUPhF9SI5IbjEQgJF+otfDD1OxcSMF//yX75XWNO2EogNBM3qH9WbR+Yu4sP+FfrtGU4Fga/5WNh/ezK9Tf43ZZG7VOackTuG7Q99R7ihvsWzkrAuJOHcGeS+8QOXPP7fqOpqmnRh0IGjBUNtQrObWLRzTGpGBkUQGRjbIQvrv7f8mxBLCrIGzWn3OKUlTcLgdfJPzTYtlRYRe8+djiY0h++57cJW1HDw0TTux6EBwHEgKqzuE9HDFYZanL+eigRcRHhDe6vONjh1NuDW8yVnG9ZkjIkh46ikcWVnkPv54q6+naVrXpgPBcSApIqnOpLJFOxbhUi5+nfrrNp3ParIyKWESa7LX4FYNV0prTEhaGtE33UTxxx9TvLTZ1E+app1gdCA4DiSFJ3Gw/CAOl4MqZxVLdi1hWtK02lxEbTE5cTL5lflsL9jecmGP6N/OI3j0aA7Nfwx7VnbLB2iadkLQgeA40Ce8D27lJqc8h8/2fUZRdZFPE8iac2rCqQjic/MQgFgsxC94Gtxucu69F+VsPGeRpmknFh0IjgM1I4cOlBzg39v+zZCoIaTFHVvuvZ5BPRkVM6pVgQAgIDGRXvPnU7l5M/kvv3xMddA0rWvQgeA4UDOpbPHOxewt3tvkmgOtNSVpCtsKtnG4onUL10f+6nwiLvgV+S/+HxWbNx9zPTRNO77pQHAcsAXZCLYEsyprFdHB0ZyTfE67nLdmlvGarDWtPrbXI49gjY8n5+57cJWWtkt9NE07PulAcBwQkdrmocsGX0aAOaBdzjuwx0B6hfbyaZZxfeawMBIWPI0jN5dD8x9DKdUuddI07fijA8Fxom9EXwJMAVw66NJ2O6eIMCVxChsObqDaVd3q44NHjybmlpspWbqUkk8aJIzVNO0EoQPBceK3o37Lc6c/hy3Y1q7nnZw4mUpnJZsOtS3Dt+3GGwlOO4lDj/0B+/797Vo3TdOODzoQHCcG9BzAqQmntvt5x/UaR5A5qNWjh2qI2UzCU0+B1UrGr6+gfMOGdq6hpmmdTQeCE1yQJYhTep/C6qzVbW7nt8bHk/zOvzH37MGBa68j74W/67TVmnYC8WsgEJFzRGSniOwRkfsb2X+niGwTkZ9F5CsR6evP+nRXk5Mmk12Wzd6ivW0+R+CAAaQsXkzkzJnkv/giB66/Hmd+fjvWUtO0zuK3QCAiZuBFYAYwFJgjIkPrFfsBSFNKjQTeB57yV326s9MSTgNgdXbrRw95M4WEEP+XP9P7iSeo3PwD+2bNovzbje1RRU3TOpE/7wjGAXuUUvuUUnZgETDTu4BSaqVSqsLz9hsg0Y/16bZ6hfYiNSqV/2W2rZ+gvh4XX0Ty4sWYw8I58JvfkP+Pf6DcviW30zTt+OPPQJAAeK+2kuXZ1pTrgGWN7RCRG0Vkk4hsysvLa8cqdh+TEyfzY96PFFcXt8v5ggYPIuX9JUScey55zz1P5g034iwsbJdza5rWsY6LzmIRuRJIA55ubL9S6hWlVJpSKi0mJqZjK3eCmJI4BbdyszZ7bbud0xQaSvzTT9Hrsceo+O470i+cRcWmtg1T1TSt8/gzEGQD3nmUEz3b6hCRM4CHgAuUUq2f9aT5ZHj0cKKCoto8jDS3PBe7y95gu4jQ87LZJL+3CAkOYv81c8l/5VXdVKRpXYg/A8F3wEARSRGRAOByoM70VBEZA7yMEQRalxlNaxWTmDg14VTWZq/F6fYtvXR+ZT7/3vZvLvvsMs54/wwu+fQS9hXta7Rs0JAhpHzwAeFnnUneM8+QOW8eziNH2vMjaJrmJ34LBEopJ3ALsALYDixWSm0VkT+IyAWeYk8DYcASEflRRHQeAz+akjiFUnspP+X91GSZCkcFn+37jJu+vIkzlpzBk989iVKKm0bdRHF1MXOWzuGLjC8aPdYcFkbCM88Q98jvqVi/gfRZF1G6ciVue8M7CU3Tjh/S1ZKJpaWlqU26HbpNyuxlnLboNK4adhV3nnRn7XaX28W3B7/ls32f8eWBL6l0VtI7tDfn9TuP81LOY0DPAYDRPHTX/+7ip7yfuHro1dx+0u1YTdZGr1X5y1ay77gDR2YmEhxMyLiTCZs0idBTTyUgJaVd0mxrmuY7EfleKdXoQic6EHQz139xPfkV+Xw08yN2FO7gs32f8Xn65+RX5hNuDees5LM4v9/5jI0bi0ka3jA6XA6e3vQ0C3cs5KS4k1gwZQHRwdGNXstdVUX5hg2Ur1tP+dq12DMyALDE9zaCwqRTCZ1wCubISH9+ZE3T0IFA8/L2trd56runSIlMIb04HYvJwuSEyZzf/3wmJ04m0Bzo03k+2/cZj61/jPCAcBZMWcDYuLEtHmPPyqZ87VrK162j/JtvcJeWgslE8IgRhHruFoJHjkAslmP9mJqm1aMDgVYrpyyHiz65iME9B3Nev/M4O/lsIgPb9hf5zsKd3LnqTnLKcrgr7S6uGHKFz00+yumk8uefKV+7jrJ1a6na8gu43ZjCwwkZN47gUaMIHjmCoGHDMIeHt6l+mqYdpQOBVodSqt3a6EvsJTy89mFWZq5kRvIM5k+cT4g1pNXncRUVUf7NN5StXUvFxu9wHDhQuy+gXz+CR4wgaMQIgkeOIDA1FVNA+yzeo2ndhQ4Eml+5lZvXfnmNF354gZSIFP427W+kRKYc0zmdR45Q9ctWKrf8TNWWX6jcsgVXTZI7q5WgwYONO4bhRnAISElBzOZ2+DSadmLSgUDrEBtyNnDf6vuwu+08Pulxzuh7RrudWymF89AhKn/eQtUvWzzPv+AuLweMhHgBKSmeRzKBNa/79sUU0vo7FE070ehAoHWYQ+WHuHPVnWzJ38Jvhv2G28behsXkn85f5XZjT0+ncssWqn7Zij09HXt6Oo6DB8Hr37WlV6+jwSE5pTZgWON7I6bjIsuKpvmdDgRah7K77Dy58UkW71pMSmQKUxOnMjFhImNjxxJg9n/bvruqCvv+/bWBoTo9HXt6Bvb0dNxlZbXlJDAQS1wclpiYJh7RWGJiMPfooQOG5jdKKXA4cFdX466sRDXzHNCvH8HDhrXpOjoQaJ1iWfoyluxawg+Hf8DpdhJsCSYtLo1JCZOYGD+R5IjkDp1YppTCVVBwNDhk7Md56BDOvLzaR01TUx0WC5bo6NoAYe7ZA1NoKOawMEyhYZjCwjCFhmIKq9kWamwLC8McGoroju1uyV1ZiePgQRw5B3HkZOPIycGRk4Mz5yCO3FzcFRWoykrc1dXg44p/tuuvI/buu9tUHx0ItE5V4ahg46GNrM9Zz/qc9ewv2Q9AfGg8E+InMClhEuN7jyciIKKTawruigqc+flHg8Pho0GiZrurqAh3ebkRNHz4/0esViQ4uO7Gxo5r6lwmE4ggACLGw7MNAaHuNlNAABIUhCkoqOnn4HrvAwKNegYEIAFWxFrz7NlmtRrn9byWgABMwcHdNsi5KypwFhbiKijAmZdn/Mhn53h++I0ffFf9tOxmM5a4WKzx8Vh79cYUFoopsJH/FoFBmIKDkMBA4zv2erZERbV5AqYOBNpxJas0i/U561mXvY5vD31LuaMcs5gZET2CifETmZQwiWG2YZhNx/coIOV2466o9ASFMtxlxsNVXo67rNx4X7Ovssr4sfbWyM1Q/TskpRQowO32BArl2abArRpuc7lRdjvu6uravzYbfa6qMs55jMw9etQ2oTX3MIWGHvO1/Mltt+MqKsJ1pAhXYQHO/ALjuaAQZ2EBrprn/AKchYWoysoG55CgIONHPj4ea+/eWBPij76Pj8cSG9upkyV1INCOWw63gy15W1iXs4712evZWrAVhaJHYA8mxE/gtITTmBg/EVuwrbOrekJp0C5tt6PsDpTDbrx2OBp/9nrtKivz3C157qDyjdc4HA2uZwoJMZrVoqON5rOwMEzhYUdf1zSx1TSv1W4LxewJIsrtRjmd4HajXC5wuVAuN7icxrPb5bXdhbu8HFdRMa7imkcRruJi3MXFuIpLvLYXN/rDDhjNgj17YrbZsNhsmG1RWKKOPluibZht0Vjje2Pu2fO4zqGlA4HWZRypOsKGnA2sy1nH2uy1FFYZt9dDbUM5NeFUTks4jRHRI477u4XuSimFq6ioTr9LzcOVn48zv8Bz11RWe9ekqjtmGRIJCMDcowfmyEjMkZGYekRijoisfW/uEWnc4dhsxg9/VBSmiIgTZqCADgRal+RWbrYXbmdt1lrW5azjp7yfcCs3EQERtU1Ipyac2mTSO61rUHa7pznNq3mtzBMoysuOduCbzYjJDBbjWSxmaPBsMiYWmkzGnUWE5wc+MhJTUFDnftBOpgOBdkIori5mw8ENtYEhv9KYaTwkaginJpzKuN7jGBUzimBLcAtn0rTuRwcC7YTjVm52HdnF2uy1rMlaw095P+FSLiwmCyOjR5LWK42Te52sA4OmeehAoJ3wyuxl/HD4B77L/Y7vD33P1oKtOjBomhcdCLRup9xRbgSGQ9+x6dCmOoFhRPQI0uLSSOuVRlJ4EhEBEYRZw/zWAe1yu3DjbnI1N03rCJ0WCETkHOA5wAz8Uyn1l3r7A4G3gJOAAuAypVRGc+fUgUBrizqBIXcTW/ONwOAtzBpGREAE4QHhRARGEG41nmu3eZ5FhHJ7OWWOMsod5ZQ7jr4uc5TV2VfmKKPSaQxNjAqKIi4kjrjQOOJC4ugV2st479kWGxJ7wt2tlDvKOVh2kIPlxqOouojo4GhiQ2KJCzE+c0RAxHE97PJE0SmBQETMwC7gTCAL+A6Yo5Ta5lXmt8BIpdRNInI5MEspdVlz59WBQGsP5Y5yfsr7ibyKPErsJZTaS48+V5dQYi+ps73mx7w+s5gJtYYSZg0jNMDzbK33HBAKCg5XHia3PJfcCuNRXF3c4HyRgZG1wSE6OBqTmFCeCWPez8DRbfW2gzHb2CQmBEFEmn02iQmryUqoNZQQawihFuM5xBJiPHttC7WGEmIJwWq24nK7yK/Mr/2RP1h+kINlBzlUfoic8hwOlh+k1F7a4n+LIHNQbSCsCQ4130FsSCwxITEEmYMwmUyYxYxJ6j6fKEHErdw43U6cbicOt8N4uBx13vcI7EFcaFybzt9cIPDnNLdxwB6l1D5PJRYBM4FtXmVmAvM9r98H/i4iorpae5XW5YRaQ5kYP9Hn8g63ozZIKBThAeGEWkMJMge1+Yeo0lnJ4Yq6weFQ+SHjdXkuOwt3olCeFBLU/RH3vAYa/LjXDxo1z27lNoKFos57pRR2t50KR0WdYNIcq8lqpAZXzjrbwwPCiQ+NJz40nrGxY+kd1pveoUcfkYGRFFYV1n7e3PJc4zuoMJ43527mcOVhnG5nE1duSBDMJnODIFHzAIzXmECoDZDegbLmNTSc3e19naY09n03FrS9/xs4lROHy/iBd7qdDb7Lxlw7/FruOOkOn78bX/kzECQAmV7vs4DxTZVRSjlFpBiwAfnehUTkRuBGgD59+virvprWJKvJSlRQFFFBUe12zmBLMH0j+tI3om+7nfNYuJWbKmcVFc4KKhwVVDgrKHeU176uv80kJnqF9qr9ke8V2ouwgLAWrxMfFk98WHyz9SisKuRwxeHah8PtMPpalBuXauLZ7WqwreZ83q9rfpC99zV2V+Wtub9Na4J1bTBpImjXf7aarFhMFqwma+2j9r3ZikUsWM119yVHJLf4/bZFl1glXCn1CvAKGE1DnVwdTTshmcRU2xREJ3ZVmMREdHA00cHRDLUN7byKdCP+nDudDSR5vU/0bGu0jIhYgEiMTmNN0zStg/gzEHwHDBSRFBEJAC4HPqlX5hPgGs/rS4Cvdf+Apmlax/Jb05Cnzf8WYAXG8NHXlFJbReQPwCal1CfAv4C3RWQPUIgRLDRN07QO5Nc+AqXU58Dn9bY94vW6CrjUn3XQNE3Tmndi5FfVNE3T2kwHAk3TtG5OBwJN07RuTgcCTdO0bq7LZR8VkTxgfxsPj6berOVuTH8XBv09GPT3YDiRv4e+SqmYxnZ0uUBwLERkU1NJl7ob/V0Y9Pdg0N+Dobt+D7ppSNM0rZvTgUDTNK2b626B4JXOrsBxRH8XBv09GPT3YOiW30O36iPQNE3TGupudwSapmlaPToQaJqmdXPdJhCIyDkislNE9ojI/Z1dn84iIhkiskVEfhSRbrX4s4i8JiKHReQXr21RIvJfEdntee7ZmXXsCE18D/NFJNvz7+JHETm3M+vYEUQkSURWisg2EdkqIr/zbO92/ya6RSAQETPwIjADGArMEZHuvPTRNKXU6G44XvoN4Jx62+4HvlJKDQS+8rw/0b1Bw+8B4G+efxejPZmDT3RO4C6l1FDgFOBmz+9Ct/s30S0CATAO2KOU2qeUsgOLgJmdXCetgymlVmOse+FtJvCm5/WbwIUdWafO0MT30O0opQ4qpTZ7XpcC2zHWUe92/ya6SyBIADK93md5tnVHCvhCRL4XkRs7uzLHgTil1EHP60NAXGdWppPdIiI/e5qOTvjmEG8ikgyMAb6lG/6b6C6BQDvqVKXUWIxmsptFZHJnV+h44VkmtbuOp/4H0B8YDRwE/tqptelAIhIGfADcrpQq8d7XXf5NdJdAkA0keb1P9GzrdpRS2Z7nw8BHGM1m3VmuiPQG8Dwf7uT6dAqlVK5SyqWUcgOv0k3+XYiIFSMIvKOU+tCzudv9m+gugeA7YKCIpIhIAMbayJ90cp06nIiEikh4zWvgLOCX5o864X0CXON5fQ3wn06sS6ep+eHzmEU3+HchIoKxbvp2pdQzXru63b+JbjOz2DMc7lnADLymlHqic2vU8USkH8ZdABjrVb/bnb4HEVkITMVINZwLPAp8DCwG+mCkN5+tlDqhO1Kb+B6mYjQLKSAD+H9e7eQnJBE5FVgDbAHcns0PYvQTdK9/E90lEGiapmmN6y5NQ5qmaVoTdCDQNE3r5nQg0DRN6+Z0INA0TevmdCDQNE3r5nQg0LR6RMTllYXzx/bMVisiyd5ZPzXteGDp7Apo2nGoUik1urMroWkdRd8RaJqPPGs5POVZz2GjiAzwbE8Wka89Cdu+EpE+nu1xIvKRiPzkeUz0nMosIq96cuB/ISLBnfahNA0dCDStMcH1moYu89pXrJQaAfwdY6Y6wAvAm0qpkcA7wPOe7c8D/1NKjQLGAls92wcCLyqlhgFFwMV+/TSa1gI9s1jT6hGRMqVUWCPbM4DTlVL7PMnKDimlbCKSD/RWSjk82w8qpaJFJA9IVEpVe50jGfivZ9ETROQ+wKqUerwDPpqmNUrfEWha66gmXrdGtddrF7qvTutkOhBoWutc5vW8wfN6PUZGW4ArMBKZgbHM4TwwlksVkciOqqSmtYb+S0TTGgoWkR+93i9XStUMIe0pIj9j/FU/x7PtVuB1EbkHyAN+49n+O+AVEbkO4y//eRiLvmjacUX3EWiajzx9BGlKqfzOroumtSfdNKRpmtbN6TsCTdO0bk7fEWiapnVzOhBomqZ1czoQaJqmdXM6EGiapnVzOhBomqZ1c/8fgsLZ8UB6/1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'MDD' -> 1, 'HC' -> 0\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN (samples, timesteps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['HC', 'MDD']))\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a2743",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71271aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f18b645",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d1ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
